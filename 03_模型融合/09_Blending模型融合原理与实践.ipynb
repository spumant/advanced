{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基础数据科学运算库\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 可视化库\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 时间模块\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# sklearn库\n",
    "# 数据预处理\n",
    "from sklearn import preprocessing\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# 实用函数\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    recall_score,\n",
    "    precision_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 常用评估器\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# 网格搜索\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 自定义评估器支持模块\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin\n",
    "\n",
    "# 自定义模块\n",
    "from telcoFunc import *\n",
    "from manual_ensemble import *\n",
    "\n",
    "# 导入特征衍生模块\n",
    "import features_creation as fc\n",
    "from features_creation import *\n",
    "\n",
    "# re模块相关\n",
    "import inspect, re\n",
    "\n",
    "# 其他模块\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "from joblib import dump, load\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from hyperopt import hp, fmin, tpe, Trials\n",
    "from numpy.random import RandomState\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "tcc = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "\n",
    "# 标注连续/离散字段\n",
    "# 离散字段\n",
    "category_cols = [\n",
    "    'gender',\n",
    "    'SeniorCitizen',\n",
    "    'Partner',\n",
    "    'Dependents',\n",
    "    'PhoneService',\n",
    "    'MultipleLines',\n",
    "    'InternetService',\n",
    "    'OnlineSecurity',\n",
    "    'OnlineBackup',\n",
    "    'DeviceProtection',\n",
    "    'TechSupport',\n",
    "    'StreamingTV',\n",
    "    'StreamingMovies',\n",
    "    'Contract',\n",
    "    'PaperlessBilling',\n",
    "    'PaymentMethod',\n",
    "]\n",
    "\n",
    "# 连续字段\n",
    "numeric_cols = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "\n",
    "# 标签\n",
    "target = 'Churn'\n",
    "\n",
    "# ID列\n",
    "ID_col = 'customerID'\n",
    "\n",
    "# 验证是否划分能完全\n",
    "assert len(category_cols) + len(numeric_cols) + 2 == tcc.shape[1]\n",
    "\n",
    "# 连续字段转化\n",
    "tcc['TotalCharges'] = (\n",
    "    tcc['TotalCharges'].apply(lambda x: x if x != ' ' else np.nan).astype(float)\n",
    ")\n",
    "tcc['MonthlyCharges'] = tcc['MonthlyCharges'].astype(float)\n",
    "\n",
    "# 缺失值填补\n",
    "tcc['TotalCharges'] = tcc['TotalCharges'].fillna(0)\n",
    "\n",
    "# 标签值手动转化\n",
    "tcc['Churn'].replace(to_replace='Yes', value=1, inplace=True)\n",
    "tcc['Churn'].replace(to_replace='No', value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = tcc.drop(columns=[ID_col, target]).copy()\n",
    "labels = tcc['Churn'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集和测试集\n",
    "train, test = train_test_split(tcc, random_state=22)\n",
    "\n",
    "X_train = train.drop(columns=[ID_col, target]).copy()\n",
    "X_test = test.drop(columns=[ID_col, target]).copy()\n",
    "\n",
    "y_train = train['Churn'].copy()\n",
    "y_test = test['Churn'].copy()\n",
    "\n",
    "X_train_seq = pd.DataFrame()\n",
    "X_test_seq = pd.DataFrame()\n",
    "\n",
    "# 年份衍生\n",
    "X_train_seq['tenure_year'] = ((72 - X_train['tenure']) // 12) + 2014\n",
    "X_test_seq['tenure_year'] = ((72 - X_test['tenure']) // 12) + 2014\n",
    "\n",
    "# 月份衍生\n",
    "X_train_seq['tenure_month'] = (72 - X_train['tenure']) % 12 + 1\n",
    "X_test_seq['tenure_month'] = (72 - X_test['tenure']) % 12 + 1\n",
    "\n",
    "# 季度衍生\n",
    "X_train_seq['tenure_quarter'] = ((X_train_seq['tenure_month'] - 1) // 3) + 1\n",
    "X_test_seq['tenure_quarter'] = ((X_test_seq['tenure_month'] - 1) // 3) + 1\n",
    "\n",
    "# 独热编码\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "enc.fit(X_train_seq)\n",
    "\n",
    "seq_new = list(X_train_seq.columns)\n",
    "\n",
    "# 创建带有列名称的独热编码之后的df\n",
    "X_train_seq = pd.DataFrame(\n",
    "    enc.transform(X_train_seq).toarray(), columns=cate_colName(enc, seq_new, drop=None)\n",
    ")\n",
    "\n",
    "X_test_seq = pd.DataFrame(\n",
    "    enc.transform(X_test_seq).toarray(), columns=cate_colName(enc, seq_new, drop=None)\n",
    ")\n",
    "\n",
    "# 调整index\n",
    "X_train_seq.index = X_train.index\n",
    "X_test_seq.index = X_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ord_enc = OrdinalEncoder()\n",
    "ord_enc.fit(X_train[category_cols])\n",
    "\n",
    "X_train_OE = pd.DataFrame(\n",
    "    ord_enc.transform(X_train[category_cols]), columns=category_cols\n",
    ")\n",
    "X_train_OE.index = X_train.index\n",
    "X_train_OE = pd.concat([X_train_OE, X_train[numeric_cols]], axis=1)\n",
    "\n",
    "X_test_OE = pd.DataFrame(\n",
    "    ord_enc.transform(X_test[category_cols]), columns=category_cols\n",
    ")\n",
    "X_test_OE.index = X_test.index\n",
    "X_test_OE = pd.concat([X_test_OE, X_test[numeric_cols]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 本节新增第三方库\n",
    "from joblib import dump, load\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from hyperopt import hp, fmin, tpe\n",
    "from numpy.random import RandomState\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VotingClassifier_threshold(BaseEstimator, ClassifierMixin, TransformerMixin):\n",
    "    def __init__(self, estimators, voting=\"hard\", weights=None, thr=0.5):\n",
    "        self.estimators = estimators\n",
    "        self.voting = voting\n",
    "        self.weights = weights\n",
    "        self.thr = thr\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        VC = VotingClassifier(\n",
    "            estimators=self.estimators, voting=self.voting, weights=self.weights\n",
    "        )\n",
    "\n",
    "        VC.fit(X, y)\n",
    "        self.clf = VC\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        if self.voting == \"soft\":\n",
    "            res_proba = self.clf.predict_proba(X)\n",
    "        else:\n",
    "            res_proba = None\n",
    "        return res_proba\n",
    "\n",
    "    def predict(self, X):\n",
    "        if self.voting == \"soft\":\n",
    "            res = (self.clf.predict_proba(X)[:, 1] >= self.thr) * 1\n",
    "        else:\n",
    "            res = self.clf.predict(X)\n",
    "        return res\n",
    "\n",
    "    def score(self, X, y):\n",
    "        acc = accuracy_score(self.predict(X), y)\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化KFold评估器\n",
    "kf = KFold(n_splits=5, random_state=12, shuffle=True)\n",
    "\n",
    "# 重置训练集和测试集的index\n",
    "X_train_OE = X_train_OE.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "\n",
    "train_part_index_l = []\n",
    "eval_index_l = []\n",
    "\n",
    "for train_part_index, eval_index in kf.split(X_train_OE, y_train):\n",
    "    train_part_index_l.append(train_part_index)\n",
    "    eval_index_l.append(eval_index)\n",
    "\n",
    "# 训练集特征\n",
    "X_train1 = X_train_OE.loc[train_part_index_l[0]]\n",
    "X_train2 = X_train_OE.loc[train_part_index_l[1]]\n",
    "X_train3 = X_train_OE.loc[train_part_index_l[2]]\n",
    "X_train4 = X_train_OE.loc[train_part_index_l[3]]\n",
    "X_train5 = X_train_OE.loc[train_part_index_l[4]]\n",
    "\n",
    "# 验证集特征\n",
    "X_eval1 = X_train_OE.loc[eval_index_l[0]]\n",
    "X_eval2 = X_train_OE.loc[eval_index_l[1]]\n",
    "X_eval3 = X_train_OE.loc[eval_index_l[2]]\n",
    "X_eval4 = X_train_OE.loc[eval_index_l[3]]\n",
    "X_eval5 = X_train_OE.loc[eval_index_l[4]]\n",
    "\n",
    "# 训练集标签\n",
    "y_train1 = y_train.loc[train_part_index_l[0]]\n",
    "y_train2 = y_train.loc[train_part_index_l[1]]\n",
    "y_train3 = y_train.loc[train_part_index_l[2]]\n",
    "y_train4 = y_train.loc[train_part_index_l[3]]\n",
    "y_train5 = y_train.loc[train_part_index_l[4]]\n",
    "\n",
    "# 验证集标签\n",
    "y_eval1 = y_train.loc[eval_index_l[0]]\n",
    "y_eval2 = y_train.loc[eval_index_l[1]]\n",
    "y_eval3 = y_train.loc[eval_index_l[2]]\n",
    "y_eval4 = y_train.loc[eval_index_l[3]]\n",
    "y_eval5 = y_train.loc[eval_index_l[4]]\n",
    "\n",
    "train_set = [\n",
    "    (X_train1, y_train1),\n",
    "    (X_train2, y_train2),\n",
    "    (X_train3, y_train3),\n",
    "    (X_train4, y_train4),\n",
    "    (X_train5, y_train5),\n",
    "]\n",
    "\n",
    "eval_set = [\n",
    "    (X_eval1, y_eval1),\n",
    "    (X_eval2, y_eval2),\n",
    "    (X_eval3, y_eval3),\n",
    "    (X_eval4, y_eval4),\n",
    "    (X_eval5, y_eval5),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机森林模型组\n",
    "grid_RF_1 = load(\"./model/grid_RF_1.joblib\")\n",
    "grid_RF_2 = load(\"./model/grid_RF_2.joblib\")\n",
    "grid_RF_3 = load(\"./model/grid_RF_3.joblib\")\n",
    "grid_RF_4 = load(\"./model/grid_RF_4.joblib\")\n",
    "grid_RF_5 = load(\"./model/grid_RF_5.joblib\")\n",
    "\n",
    "RF_1 = grid_RF_1.best_estimator_\n",
    "RF_2 = grid_RF_2.best_estimator_\n",
    "RF_3 = grid_RF_3.best_estimator_\n",
    "RF_4 = grid_RF_4.best_estimator_\n",
    "RF_5 = grid_RF_5.best_estimator_\n",
    "\n",
    "RF_l = [RF_1, RF_2, RF_3, RF_4, RF_5]\n",
    "\n",
    "# 决策树模型组\n",
    "grid_tree_1 = load(\"./model/grid_tree_1.joblib\")\n",
    "grid_tree_2 = load(\"./model/grid_tree_2.joblib\")\n",
    "grid_tree_3 = load(\"./model/grid_tree_3.joblib\")\n",
    "grid_tree_4 = load(\"./model/grid_tree_4.joblib\")\n",
    "grid_tree_5 = load(\"./model/grid_tree_5.joblib\")\n",
    "\n",
    "tree_1 = grid_tree_1.best_estimator_\n",
    "tree_2 = grid_tree_2.best_estimator_\n",
    "tree_3 = grid_tree_3.best_estimator_\n",
    "tree_4 = grid_tree_4.best_estimator_\n",
    "tree_5 = grid_tree_5.best_estimator_\n",
    "\n",
    "tree_l = [tree_1, tree_2, tree_3, tree_4, tree_5]\n",
    "\n",
    "# 逻辑回归模型组\n",
    "grid_lr_1 = load(\"./model/grid_lr_1.joblib\")\n",
    "grid_lr_2 = load(\"./model/grid_lr_2.joblib\")\n",
    "grid_lr_3 = load(\"./model/grid_lr_3.joblib\")\n",
    "grid_lr_4 = load(\"./model/grid_lr_4.joblib\")\n",
    "grid_lr_5 = load(\"./model/grid_lr_5.joblib\")\n",
    "\n",
    "lr_1 = grid_lr_1.best_estimator_\n",
    "lr_2 = grid_lr_2.best_estimator_\n",
    "lr_3 = grid_lr_3.best_estimator_\n",
    "lr_4 = grid_lr_4.best_estimator_\n",
    "lr_5 = grid_lr_5.best_estimator_\n",
    "\n",
    "lr_l = [lr_1, lr_2, lr_3, lr_4, lr_5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval1_predict_proba_RF = pd.Series(\n",
    "    RF_l[0].predict_proba(X_eval1)[:, 1], index=X_eval1.index\n",
    ")\n",
    "eval2_predict_proba_RF = pd.Series(\n",
    "    RF_l[1].predict_proba(X_eval2)[:, 1], index=X_eval2.index\n",
    ")\n",
    "eval3_predict_proba_RF = pd.Series(\n",
    "    RF_l[2].predict_proba(X_eval3)[:, 1], index=X_eval3.index\n",
    ")\n",
    "eval4_predict_proba_RF = pd.Series(\n",
    "    RF_l[3].predict_proba(X_eval4)[:, 1], index=X_eval4.index\n",
    ")\n",
    "eval5_predict_proba_RF = pd.Series(\n",
    "    RF_l[4].predict_proba(X_eval5)[:, 1], index=X_eval5.index\n",
    ")\n",
    "\n",
    "eval_predict_proba_RF = pd.concat(\n",
    "    [\n",
    "        eval1_predict_proba_RF,\n",
    "        eval2_predict_proba_RF,\n",
    "        eval3_predict_proba_RF,\n",
    "        eval4_predict_proba_RF,\n",
    "        eval5_predict_proba_RF,\n",
    "    ]\n",
    ").sort_index()\n",
    "\n",
    "eval1_predict_proba_tree = pd.Series(\n",
    "    tree_l[0].predict_proba(X_eval1)[:, 1], index=X_eval1.index\n",
    ")\n",
    "eval2_predict_proba_tree = pd.Series(\n",
    "    tree_l[1].predict_proba(X_eval2)[:, 1], index=X_eval2.index\n",
    ")\n",
    "eval3_predict_proba_tree = pd.Series(\n",
    "    tree_l[2].predict_proba(X_eval3)[:, 1], index=X_eval3.index\n",
    ")\n",
    "eval4_predict_proba_tree = pd.Series(\n",
    "    tree_l[3].predict_proba(X_eval4)[:, 1], index=X_eval4.index\n",
    ")\n",
    "eval5_predict_proba_tree = pd.Series(\n",
    "    tree_l[4].predict_proba(X_eval5)[:, 1], index=X_eval5.index\n",
    ")\n",
    "\n",
    "eval_predict_proba_tree = pd.concat(\n",
    "    [\n",
    "        eval1_predict_proba_tree,\n",
    "        eval2_predict_proba_tree,\n",
    "        eval3_predict_proba_tree,\n",
    "        eval4_predict_proba_tree,\n",
    "        eval5_predict_proba_tree,\n",
    "    ]\n",
    ").sort_index()\n",
    "\n",
    "eval1_predict_proba_lr = pd.Series(\n",
    "    lr_l[0].predict_proba(X_eval1)[:, 1], index=X_eval1.index\n",
    ")\n",
    "eval2_predict_proba_lr = pd.Series(\n",
    "    lr_l[1].predict_proba(X_eval2)[:, 1], index=X_eval2.index\n",
    ")\n",
    "eval3_predict_proba_lr = pd.Series(\n",
    "    lr_l[2].predict_proba(X_eval3)[:, 1], index=X_eval3.index\n",
    ")\n",
    "eval4_predict_proba_lr = pd.Series(\n",
    "    lr_l[3].predict_proba(X_eval4)[:, 1], index=X_eval4.index\n",
    ")\n",
    "eval5_predict_proba_lr = pd.Series(\n",
    "    lr_l[4].predict_proba(X_eval5)[:, 1], index=X_eval5.index\n",
    ")\n",
    "\n",
    "eval_predict_proba_lr = pd.concat(\n",
    "    [\n",
    "        eval1_predict_proba_lr,\n",
    "        eval2_predict_proba_lr,\n",
    "        eval3_predict_proba_lr,\n",
    "        eval4_predict_proba_lr,\n",
    "        eval5_predict_proba_lr,\n",
    "    ]\n",
    ").sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict_proba_RF = []\n",
    "\n",
    "for i in range(5):\n",
    "    test_predict_proba_RF.append(RF_l[i].predict_proba(X_test_OE)[:, 1])\n",
    "\n",
    "test_predict_proba_RF = np.array(test_predict_proba_RF)\n",
    "test_predict_proba_RF = test_predict_proba_RF.mean(0)\n",
    "\n",
    "test_predict_proba_tree = []\n",
    "\n",
    "for i in range(5):\n",
    "    test_predict_proba_tree.append(tree_l[i].predict_proba(X_test_OE)[:, 1])\n",
    "\n",
    "test_predict_proba_tree = np.array(test_predict_proba_tree)\n",
    "test_predict_proba_tree = test_predict_proba_tree.mean(0)\n",
    "\n",
    "test_predict_proba_lr = []\n",
    "\n",
    "for i in range(5):\n",
    "    test_predict_proba_lr.append(lr_l[i].predict_proba(X_test_OE)[:, 1])\n",
    "\n",
    "test_predict_proba_lr = np.array(test_predict_proba_lr)\n",
    "test_predict_proba_lr = test_predict_proba_lr.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_train2, y_train1, y_train2 = train_test_split(\n",
    "    X_train_OE, y_train, test_size=0.2, random_state=12\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4225, 19)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1057, 19)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.50578761100769\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "parameter_space = {\n",
    "    \"min_samples_leaf\": range(7, 10),\n",
    "    \"min_samples_split\": range(2, 4),\n",
    "    \"max_depth\": range(5, 8),\n",
    "    \"max_leaf_nodes\": [None] + list(range(32, 49, 2)),\n",
    "    \"n_estimators\": range(9, 12),\n",
    "    \"max_features\": [\"sqrt\", \"log2\"] + list(range(4, 8)),\n",
    "    \"max_samples\": [None, 0.55, 0.6, 0.65],\n",
    "}\n",
    "\n",
    "RF_blending = RandomForestClassifier(random_state=12)\n",
    "grid_RF_blending = GridSearchCV(RF_blending, parameter_space, n_jobs=-1)\n",
    "\n",
    "grid_RF_blending.fit(X_train1, y_train1)\n",
    "\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 6,\n",
       " 'max_features': 6,\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': 0.6,\n",
       " 'min_samples_leaf': 8,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 10}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_RF_blending.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8191715976331361, 0.8136234626300851, 0.7830777967064169)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_RF_blending.score(X_train1, y_train1), grid_RF_blending.score(\n",
    "    X_train2, y_train2\n",
    "), grid_RF_blending.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "447.3558382987976 s\n"
     ]
    }
   ],
   "source": [
    "logistic_pre = ColumnTransformer(\n",
    "    [\n",
    "        (\"cat\", preprocessing.OneHotEncoder(drop=\"if_binary\"), category_cols),\n",
    "        (\"num\", \"passthrough\", numeric_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "num_pre = [\n",
    "    \"passthrough\",\n",
    "    preprocessing.StandardScaler(),\n",
    "    preprocessing.KBinsDiscretizer(n_bins=3, encode=\"ordinal\", strategy=\"kmeans\"),\n",
    "]\n",
    "\n",
    "logistic_blending = logit_threshold(max_iter=int(1e8))\n",
    "\n",
    "logistic_pipe = make_pipeline(logistic_pre, logistic_blending)\n",
    "\n",
    "cw_l = [None, \"balanced\"]\n",
    "\n",
    "logistic_param = [\n",
    "    {\n",
    "        \"columntransformer__num\": num_pre,\n",
    "        \"logit_threshold__thr\": np.arange(0.1, 1, 0.1).tolist(),\n",
    "        \"logit_threshold__penalty\": [\"l1\"],\n",
    "        \"logit_threshold__C\": np.arange(0.1, 1.1, 0.1).tolist(),\n",
    "        \"logit_threshold__solver\": [\"saga\"],\n",
    "        \"logit_threshold__class_weight\": cw_l,\n",
    "    },\n",
    "    {\n",
    "        \"columntransformer__num\": num_pre,\n",
    "        \"logit_threshold__thr\": np.arange(0.1, 1, 0.1).tolist(),\n",
    "        \"logit_threshold__penalty\": [\"l2\"],\n",
    "        \"logit_threshold__C\": np.arange(0.1, 1.1, 0.1).tolist(),\n",
    "        \"logit_threshold__solver\": [\"lbfgs\", \"newton-cg\", \"sag\", \"saga\"],\n",
    "        \"logit_threshold__class_weight\": cw_l,\n",
    "    },\n",
    "]\n",
    "\n",
    "# 实例化网格搜索评估器\n",
    "grid_lr_blending = GridSearchCV(\n",
    "    estimator=logistic_pipe, param_grid=logistic_param, scoring=\"accuracy\", n_jobs=-1\n",
    ")\n",
    "\n",
    "s = time.time()\n",
    "grid_lr_blending.fit(X_train1, y_train1)\n",
    "print(time.time() - s, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8073372781065089"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_lr_blending.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8073372781065089, 0.8183538315988647, 0.7825099375354913)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_lr_blending.score(X_train1, y_train1), grid_lr_blending.score(\n",
    "    X_train2, y_train2\n",
    "), grid_lr_blending.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model = DecisionTreeClassifier(random_state=12)\n",
    "\n",
    "tree_param = {\n",
    "    \"max_depth\": np.arange(2, 16, 1).tolist(),\n",
    "    \"min_samples_split\": np.arange(2, 5, 1).tolist(),\n",
    "    \"min_samples_leaf\": np.arange(1, 4, 1).tolist(),\n",
    "    \"max_leaf_nodes\": np.arange(6, 30, 1).tolist(),\n",
    "}\n",
    "\n",
    "grid_tree_blending = GridSearchCV(\n",
    "    estimator=tree_model, param_grid=tree_param, n_jobs=12\n",
    ").fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8011834319526627"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_tree_blending.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8137278106508876, 0.7994323557237465, 0.7717206132879046)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_tree_blending.score(X_train1, y_train1), grid_tree_blending.score(\n",
    "    X_train2, y_train2\n",
    "), grid_tree_blending.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_oof_blending = pd.DataFrame(\n",
    "    {\n",
    "        \"lr_oof_blending\": grid_lr_blending.predict_proba(X_train2)[:, 1],\n",
    "        \"RF_oof_blending\": grid_RF_blending.predict_proba(X_train2)[:, 1],\n",
    "        \"tree_oof_blending\": grid_tree_blending.predict_proba(X_train2)[:, 1],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict_blending = pd.DataFrame(\n",
    "    {\n",
    "        \"lr_oof_blending\": grid_lr_blending.predict_proba(X_test_OE)[:, 1],\n",
    "        \"RF_oof_blending\": grid_RF_blending.predict_proba(X_test_OE)[:, 1],\n",
    "        \"tree_oof_blending\": grid_tree_blending.predict_proba(X_test_OE)[:, 1],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results of LR-final:\n",
      "Train2-Accuracy: 0.818354, Test-Accuracy: 0.788189\n",
      "The results of tree-final:\n",
      "Train2-Accuracy: 1.000000, Test-Accuracy: 0.727428\n",
      "The results of KNN-final:\n",
      "Train2-Accuracy: 0.850520, Test-Accuracy: 0.766042\n",
      "The results of SVM-final:\n",
      "Train2-Accuracy: 0.826868, Test-Accuracy: 0.787053\n",
      "The results of GaussianNB-final:\n",
      "Train2-Accuracy: 0.807001, Test-Accuracy: 0.780239\n",
      "The results of Bagging-final:\n",
      "Train2-Accuracy: 0.977294, Test-Accuracy: 0.752413\n",
      "The results of RandomForest-final:\n",
      "Train2-Accuracy: 1.000000, Test-Accuracy: 0.764906\n",
      "The results of AdaBoost-final:\n",
      "Train2-Accuracy: 0.838221, Test-Accuracy: 0.779671\n",
      "The results of GBDT-final:\n",
      "Train2-Accuracy: 0.886471, Test-Accuracy: 0.781374\n",
      "The results of XGB-final:\n",
      "Train2-Accuracy: 0.965941, Test-Accuracy: 0.767746\n"
     ]
    }
   ],
   "source": [
    "# 逻辑回归\n",
    "lr = LogisticRegression().fit(train_oof_blending, y_train2)\n",
    "print(\"The results of LR-final:\")\n",
    "print(\n",
    "    \"Train2-Accuracy: %f, Test-Accuracy: %f\"\n",
    "    % (lr.score(train_oof_blending, y_train2), lr.score(test_predict_blending, y_test))\n",
    ")\n",
    "\n",
    "# 决策树\n",
    "tree = DecisionTreeClassifier().fit(train_oof_blending, y_train2)\n",
    "print(\"The results of tree-final:\")\n",
    "print(\n",
    "    \"Train2-Accuracy: %f, Test-Accuracy: %f\"\n",
    "    % (\n",
    "        tree.score(train_oof_blending, y_train2),\n",
    "        tree.score(test_predict_blending, y_test),\n",
    "    )\n",
    ")\n",
    "\n",
    "# KNN最近邻分类器\n",
    "from sklearn import neighbors\n",
    "\n",
    "KNN = neighbors.KNeighborsClassifier().fit(train_oof_blending, y_train2)\n",
    "print(\"The results of KNN-final:\")\n",
    "print(\n",
    "    \"Train2-Accuracy: %f, Test-Accuracy: %f\"\n",
    "    % (\n",
    "        KNN.score(train_oof_blending, y_train2),\n",
    "        KNN.score(test_predict_blending, y_test),\n",
    "    )\n",
    ")\n",
    "\n",
    "# SVM支持向量机\n",
    "from sklearn import svm\n",
    "\n",
    "SVM = svm.SVC().fit(train_oof_blending, y_train2)\n",
    "print(\"The results of SVM-final:\")\n",
    "print(\n",
    "    \"Train2-Accuracy: %f, Test-Accuracy: %f\"\n",
    "    % (\n",
    "        SVM.score(train_oof_blending, y_train2),\n",
    "        SVM.score(test_predict_blending, y_test),\n",
    "    )\n",
    ")\n",
    "\n",
    "# 朴素贝叶斯/高斯贝叶斯\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB().fit(train_oof_blending, y_train2)\n",
    "print(\"The results of GaussianNB-final:\")\n",
    "print(\n",
    "    \"Train2-Accuracy: %f, Test-Accuracy: %f\"\n",
    "    % (\n",
    "        gnb.score(train_oof_blending, y_train2),\n",
    "        gnb.score(test_predict_blending, y_test),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Bagging\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bagging = BaggingClassifier().fit(train_oof_blending, y_train2)\n",
    "print(\"The results of Bagging-final:\")\n",
    "print(\n",
    "    \"Train2-Accuracy: %f, Test-Accuracy: %f\"\n",
    "    % (\n",
    "        bagging.score(train_oof_blending, y_train2),\n",
    "        bagging.score(test_predict_blending, y_test),\n",
    "    )\n",
    ")\n",
    "\n",
    "# 随机森林\n",
    "RFC = RandomForestClassifier().fit(train_oof_blending, y_train2)\n",
    "print(\"The results of RandomForest-final:\")\n",
    "print(\n",
    "    \"Train2-Accuracy: %f, Test-Accuracy: %f\"\n",
    "    % (\n",
    "        RFC.score(train_oof_blending, y_train2),\n",
    "        RFC.score(test_predict_blending, y_test),\n",
    "    )\n",
    ")\n",
    "\n",
    "# AdaBoost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ABC = AdaBoostClassifier().fit(train_oof_blending, y_train2)\n",
    "print(\"The results of AdaBoost-final:\")\n",
    "print(\n",
    "    \"Train2-Accuracy: %f, Test-Accuracy: %f\"\n",
    "    % (\n",
    "        ABC.score(train_oof_blending, y_train2),\n",
    "        ABC.score(test_predict_blending, y_test),\n",
    "    )\n",
    ")\n",
    "\n",
    "# GBDT\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "GBC = GradientBoostingClassifier().fit(train_oof_blending, y_train2)\n",
    "print(\"The results of GBDT-final:\")\n",
    "print(\n",
    "    \"Train2-Accuracy: %f, Test-Accuracy: %f\"\n",
    "    % (\n",
    "        GBC.score(train_oof_blending, y_train2),\n",
    "        GBC.score(test_predict_blending, y_test),\n",
    "    )\n",
    ")\n",
    "\n",
    "# XGB\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "XGB = XGBClassifier().fit(train_oof_blending, y_train2)\n",
    "print(\"The results of XGB-final:\")\n",
    "print(\n",
    "    \"Train2-Accuracy: %f, Test-Accuracy: %f\"\n",
    "    % (\n",
    "        XGB.score(train_oof_blending, y_train2),\n",
    "        XGB.score(test_predict_blending, y_test),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    (\"lr\", grid_lr_blending.best_estimator_),\n",
    "    (\"tree\", grid_tree_blending.best_estimator_),\n",
    "    (\"rf\", grid_RF_blending.best_estimator_),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_oof_blending, test_predict_blending = train_cross(\n",
    "    X_train_OE, y_train, X_test_OE, estimators, blending=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results of LR-final:\n",
      "Train2-Accuracy: 0.822138, Test-Accuracy: 0.784214\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression().fit(\n",
    "    train_oof_blending.iloc[:, :-1], train_oof_blending.iloc[:, -1]\n",
    ")\n",
    "print(\"The results of LR-final:\")\n",
    "print(\n",
    "    \"Train2-Accuracy: %f, Test-Accuracy: %f\"\n",
    "    % (\n",
    "        lr.score(train_oof_blending.iloc[:, :-1], train_oof_blending.iloc[:, -1]),\n",
    "        lr.score(test_predict_blending, y_test),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = logit_threshold()\n",
    "tree = DecisionTreeClassifier()\n",
    "final_model_l = [lr, tree]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_final_param = [\n",
    "    {\n",
    "        \"thr\": np.arange(0.1, 1.1, 0.1).tolist(),\n",
    "        \"penalty\": [\"l1\"],\n",
    "        \"C\": np.arange(0.1, 1.1, 0.1).tolist(),\n",
    "        \"solver\": [\"saga\"],\n",
    "    },\n",
    "    {\n",
    "        \"thr\": np.arange(0.1, 1.1, 0.1).tolist(),\n",
    "        \"penalty\": [\"l2\"],\n",
    "        \"C\": np.arange(0.1, 1.1, 0.1).tolist(),\n",
    "        \"solver\": [\"lbfgs\", \"newton-cg\", \"sag\", \"saga\"],\n",
    "    },\n",
    "]\n",
    "\n",
    "tree_final_param = {\n",
    "    \"max_depth\": np.arange(2, 16, 1).tolist(),\n",
    "    \"min_samples_split\": np.arange(2, 5, 1).tolist(),\n",
    "    \"min_samples_leaf\": np.arange(1, 4, 1).tolist(),\n",
    "    \"max_leaf_nodes\": np.arange(6, 30, 1).tolist(),\n",
    "}\n",
    "\n",
    "param_space_l = [lr_final_param, tree_final_param]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_res_final, best_test_predict_final = final_model_opt(\n",
    "    final_model_l,\n",
    "    param_space_l,\n",
    "    train_oof_blending.iloc[:, :-1],\n",
    "    train_oof_blending.iloc[:, -1],\n",
    "    test_predict_blending,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7830777967064169"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score((best_test_predict_final >= 0.5) * 1, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_hyper = lr_cascade(lr_params_space, max_evals=50)\n",
    "tree_hyper = tree_cascade(tree_params_space)\n",
    "RF_hyper = RF_cascade(RF_params_space, max_evals=1000)\n",
    "\n",
    "estimators = [(\"lr\", lr_hyper), (\"tree\", tree_hyper), (\"rf\", RF_hyper)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_oof_blending, test_predict_blending = train_cross(\n",
    "    X_train_OE, y_train, X_test_OE, estimators=estimators, blending=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_res_final, best_test_predict_final = final_model_opt(\n",
    "    final_model_l,\n",
    "    param_space_l,\n",
    "    train_oof_blending.iloc[:, :-1],\n",
    "    train_oof_blending.iloc[:, -1],\n",
    "    test_predict_blending,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score((best_test_predict_final >= 0.5) * 1, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "极限效果测试下，一次运行约需要1个半小时。并且，最终得到的融合结果略好于单模建模结果，略差于上一小节的自动Stacking融合结果。至此，我们就完整执行了手动和自动Blending融合及优化各流程。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
