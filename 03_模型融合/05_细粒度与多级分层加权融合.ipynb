{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基础数据科学运算库\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 可视化库\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 时间模块\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# sklearn库\n",
    "# 数据预处理\n",
    "from sklearn import preprocessing\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# 实用函数\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    recall_score,\n",
    "    precision_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 常用评估器\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 网格搜索\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 自定义评估器支持模块\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin\n",
    "\n",
    "# 自定义模块\n",
    "from telcoFunc import *\n",
    "\n",
    "# 导入特征衍生模块\n",
    "import features_creation as fc\n",
    "from features_creation import *\n",
    "\n",
    "# re模块相关\n",
    "import inspect, re\n",
    "\n",
    "# 其他模块\n",
    "from tqdm import tqdm\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "tcc = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "\n",
    "# 标注连续/离散字段\n",
    "# 离散字段\n",
    "category_cols = [\n",
    "    'gender',\n",
    "    'SeniorCitizen',\n",
    "    'Partner',\n",
    "    'Dependents',\n",
    "    'PhoneService',\n",
    "    'MultipleLines',\n",
    "    'InternetService',\n",
    "    'OnlineSecurity',\n",
    "    'OnlineBackup',\n",
    "    'DeviceProtection',\n",
    "    'TechSupport',\n",
    "    'StreamingTV',\n",
    "    'StreamingMovies',\n",
    "    'Contract',\n",
    "    'PaperlessBilling',\n",
    "    'PaymentMethod',\n",
    "]\n",
    "\n",
    "# 连续字段\n",
    "numeric_cols = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "\n",
    "# 标签\n",
    "target = 'Churn'\n",
    "\n",
    "# ID列\n",
    "ID_col = 'customerID'\n",
    "\n",
    "# 验证是否划分能完全\n",
    "assert len(category_cols) + len(numeric_cols) + 2 == tcc.shape[1]\n",
    "\n",
    "# 连续字段转化\n",
    "tcc['TotalCharges'] = (\n",
    "    tcc['TotalCharges'].apply(lambda x: x if x != ' ' else np.nan).astype(float)\n",
    ")\n",
    "tcc['MonthlyCharges'] = tcc['MonthlyCharges'].astype(float)\n",
    "\n",
    "# 缺失值填补\n",
    "tcc['TotalCharges'] = tcc['TotalCharges'].fillna(0)\n",
    "\n",
    "# 标签值手动转化\n",
    "tcc['Churn'].replace(to_replace='Yes', value=1, inplace=True)\n",
    "tcc['Churn'].replace(to_replace='No', value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = tcc.drop(columns=[ID_col, target]).copy()\n",
    "labels = tcc['Churn'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集和测试集\n",
    "train, test = train_test_split(tcc, random_state=22)\n",
    "\n",
    "X_train = train.drop(columns=[ID_col, target]).copy()\n",
    "X_test = test.drop(columns=[ID_col, target]).copy()\n",
    "\n",
    "y_train = train['Churn'].copy()\n",
    "y_test = test['Churn'].copy()\n",
    "\n",
    "X_train_seq = pd.DataFrame()\n",
    "X_test_seq = pd.DataFrame()\n",
    "\n",
    "# 年份衍生\n",
    "X_train_seq['tenure_year'] = ((72 - X_train['tenure']) // 12) + 2014\n",
    "X_test_seq['tenure_year'] = ((72 - X_test['tenure']) // 12) + 2014\n",
    "\n",
    "# 月份衍生\n",
    "X_train_seq['tenure_month'] = (72 - X_train['tenure']) % 12 + 1\n",
    "X_test_seq['tenure_month'] = (72 - X_test['tenure']) % 12 + 1\n",
    "\n",
    "# 季度衍生\n",
    "X_train_seq['tenure_quarter'] = ((X_train_seq['tenure_month'] - 1) // 3) + 1\n",
    "X_test_seq['tenure_quarter'] = ((X_test_seq['tenure_month'] - 1) // 3) + 1\n",
    "\n",
    "# 独热编码\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "enc.fit(X_train_seq)\n",
    "\n",
    "seq_new = list(X_train_seq.columns)\n",
    "\n",
    "# 创建带有列名称的独热编码之后的df\n",
    "X_train_seq = pd.DataFrame(\n",
    "    enc.transform(X_train_seq).toarray(), columns=cate_colName(enc, seq_new, drop=None)\n",
    ")\n",
    "\n",
    "X_test_seq = pd.DataFrame(\n",
    "    enc.transform(X_test_seq).toarray(), columns=cate_colName(enc, seq_new, drop=None)\n",
    ")\n",
    "\n",
    "# 调整index\n",
    "X_train_seq.index = X_train.index\n",
    "X_test_seq.index = X_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ord_enc = OrdinalEncoder()\n",
    "ord_enc.fit(X_train[category_cols])\n",
    "\n",
    "X_train_OE = pd.DataFrame(\n",
    "    ord_enc.transform(X_train[category_cols]), columns=category_cols\n",
    ")\n",
    "X_train_OE.index = X_train.index\n",
    "X_train_OE = pd.concat([X_train_OE, X_train[numeric_cols]], axis=1)\n",
    "\n",
    "X_test_OE = pd.DataFrame(\n",
    "    ord_enc.transform(X_test[category_cols]), columns=category_cols\n",
    ")\n",
    "X_test_OE.index = X_test.index\n",
    "X_test_OE = pd.concat([X_test_OE, X_test[numeric_cols]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 本节新增第三方库\n",
    "from joblib import dump, load\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from hyperopt import hp, fmin, tpe\n",
    "from numpy.random import RandomState\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VotingClassifier_threshold(BaseEstimator, ClassifierMixin, TransformerMixin):\n",
    "    def __init__(self, estimators, voting=\"hard\", weights=None, thr=0.5):\n",
    "        self.estimators = estimators\n",
    "        self.voting = voting\n",
    "        self.weights = weights\n",
    "        self.thr = thr\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        VC = VotingClassifier(\n",
    "            estimators=self.estimators, voting=self.voting, weights=self.weights\n",
    "        )\n",
    "\n",
    "        VC.fit(X, y)\n",
    "        self.clf = VC\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.clf.predict_proba(X) if self.voting == \"soft\" else None\n",
    "\n",
    "    def predict(self, X):\n",
    "        return (\n",
    "            (self.clf.predict_proba(X)[:, 1] >= self.thr) * 1\n",
    "            if self.voting == \"soft\"\n",
    "            else self.clf.predict(X)\n",
    "        )\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return accuracy_score(self.predict(X), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化KFold评估器\n",
    "kf = KFold(n_splits=5, random_state=12, shuffle=True)\n",
    "\n",
    "# 重置训练集和测试集的index\n",
    "X_train_OE = X_train_OE.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "\n",
    "train_part_index_l = []\n",
    "eval_index_l = []\n",
    "\n",
    "for train_part_index, eval_index in kf.split(X_train_OE, y_train):\n",
    "    train_part_index_l.append(train_part_index)\n",
    "    eval_index_l.append(eval_index)\n",
    "\n",
    "# 训练集特征\n",
    "X_train1 = X_train_OE.loc[train_part_index_l[0]]\n",
    "X_train2 = X_train_OE.loc[train_part_index_l[1]]\n",
    "X_train3 = X_train_OE.loc[train_part_index_l[2]]\n",
    "X_train4 = X_train_OE.loc[train_part_index_l[3]]\n",
    "X_train5 = X_train_OE.loc[train_part_index_l[4]]\n",
    "\n",
    "# 验证集特征\n",
    "X_eval1 = X_train_OE.loc[eval_index_l[0]]\n",
    "X_eval2 = X_train_OE.loc[eval_index_l[1]]\n",
    "X_eval3 = X_train_OE.loc[eval_index_l[2]]\n",
    "X_eval4 = X_train_OE.loc[eval_index_l[3]]\n",
    "X_eval5 = X_train_OE.loc[eval_index_l[4]]\n",
    "\n",
    "# 训练集标签\n",
    "y_train1 = y_train.loc[train_part_index_l[0]]\n",
    "y_train2 = y_train.loc[train_part_index_l[1]]\n",
    "y_train3 = y_train.loc[train_part_index_l[2]]\n",
    "y_train4 = y_train.loc[train_part_index_l[3]]\n",
    "y_train5 = y_train.loc[train_part_index_l[4]]\n",
    "\n",
    "# 验证集标签\n",
    "y_eval1 = y_train.loc[eval_index_l[0]]\n",
    "y_eval2 = y_train.loc[eval_index_l[1]]\n",
    "y_eval3 = y_train.loc[eval_index_l[2]]\n",
    "y_eval4 = y_train.loc[eval_index_l[3]]\n",
    "y_eval5 = y_train.loc[eval_index_l[4]]\n",
    "\n",
    "train_set = [\n",
    "    (X_train1, y_train1),\n",
    "    (X_train2, y_train2),\n",
    "    (X_train3, y_train3),\n",
    "    (X_train4, y_train4),\n",
    "    (X_train5, y_train5),\n",
    "]\n",
    "\n",
    "eval_set = [\n",
    "    (X_eval1, y_eval1),\n",
    "    (X_eval2, y_eval2),\n",
    "    (X_eval3, y_eval3),\n",
    "    (X_eval4, y_eval4),\n",
    "    (X_eval5, y_eval5),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机森林模型组\n",
    "grid_RF_1 = load(\"./model/grid_RF_1.joblib\")\n",
    "grid_RF_2 = load(\"./model/grid_RF_2.joblib\")\n",
    "grid_RF_3 = load(\"./model/grid_RF_3.joblib\")\n",
    "grid_RF_4 = load(\"./model/grid_RF_4.joblib\")\n",
    "grid_RF_5 = load(\"./model/grid_RF_5.joblib\")\n",
    "\n",
    "RF_1 = grid_RF_1.best_estimator_\n",
    "RF_2 = grid_RF_2.best_estimator_\n",
    "RF_3 = grid_RF_3.best_estimator_\n",
    "RF_4 = grid_RF_4.best_estimator_\n",
    "RF_5 = grid_RF_5.best_estimator_\n",
    "\n",
    "RF_l = [RF_1, RF_2, RF_3, RF_4, RF_5]\n",
    "\n",
    "# 决策树模型组\n",
    "grid_tree_1 = load(\"./model/grid_tree_1.joblib\")\n",
    "grid_tree_2 = load(\"./model/grid_tree_2.joblib\")\n",
    "grid_tree_3 = load(\"./model/grid_tree_3.joblib\")\n",
    "grid_tree_4 = load(\"./model/grid_tree_4.joblib\")\n",
    "grid_tree_5 = load(\"./model/grid_tree_5.joblib\")\n",
    "\n",
    "tree_1 = grid_tree_1.best_estimator_\n",
    "tree_2 = grid_tree_2.best_estimator_\n",
    "tree_3 = grid_tree_3.best_estimator_\n",
    "tree_4 = grid_tree_4.best_estimator_\n",
    "tree_5 = grid_tree_5.best_estimator_\n",
    "\n",
    "tree_l = [tree_1, tree_2, tree_3, tree_4, tree_5]\n",
    "\n",
    "# 逻辑回归模型组\n",
    "grid_lr_1 = load(\"./model/grid_lr_1.joblib\")\n",
    "grid_lr_2 = load(\"./model/grid_lr_2.joblib\")\n",
    "grid_lr_3 = load(\"./model/grid_lr_3.joblib\")\n",
    "grid_lr_4 = load(\"./model/grid_lr_4.joblib\")\n",
    "grid_lr_5 = load(\"./model/grid_lr_5.joblib\")\n",
    "\n",
    "lr_1 = grid_lr_1.best_estimator_\n",
    "lr_2 = grid_lr_2.best_estimator_\n",
    "lr_3 = grid_lr_3.best_estimator_\n",
    "lr_4 = grid_lr_4.best_estimator_\n",
    "lr_5 = grid_lr_5.best_estimator_\n",
    "\n",
    "lr_l = [lr_1, lr_2, lr_3, lr_4, lr_5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval1_predict_proba_RF = pd.Series(\n",
    "    RF_l[0].predict_proba(X_eval1)[:, 1], index=X_eval1.index\n",
    ")\n",
    "eval2_predict_proba_RF = pd.Series(\n",
    "    RF_l[1].predict_proba(X_eval2)[:, 1], index=X_eval2.index\n",
    ")\n",
    "eval3_predict_proba_RF = pd.Series(\n",
    "    RF_l[2].predict_proba(X_eval3)[:, 1], index=X_eval3.index\n",
    ")\n",
    "eval4_predict_proba_RF = pd.Series(\n",
    "    RF_l[3].predict_proba(X_eval4)[:, 1], index=X_eval4.index\n",
    ")\n",
    "eval5_predict_proba_RF = pd.Series(\n",
    "    RF_l[4].predict_proba(X_eval5)[:, 1], index=X_eval5.index\n",
    ")\n",
    "\n",
    "eval_predict_proba_RF = pd.concat(\n",
    "    [\n",
    "        eval1_predict_proba_RF,\n",
    "        eval2_predict_proba_RF,\n",
    "        eval3_predict_proba_RF,\n",
    "        eval4_predict_proba_RF,\n",
    "        eval5_predict_proba_RF,\n",
    "    ]\n",
    ").sort_index()\n",
    "\n",
    "eval1_predict_proba_tree = pd.Series(\n",
    "    tree_l[0].predict_proba(X_eval1)[:, 1], index=X_eval1.index\n",
    ")\n",
    "eval2_predict_proba_tree = pd.Series(\n",
    "    tree_l[1].predict_proba(X_eval2)[:, 1], index=X_eval2.index\n",
    ")\n",
    "eval3_predict_proba_tree = pd.Series(\n",
    "    tree_l[2].predict_proba(X_eval3)[:, 1], index=X_eval3.index\n",
    ")\n",
    "eval4_predict_proba_tree = pd.Series(\n",
    "    tree_l[3].predict_proba(X_eval4)[:, 1], index=X_eval4.index\n",
    ")\n",
    "eval5_predict_proba_tree = pd.Series(\n",
    "    tree_l[4].predict_proba(X_eval5)[:, 1], index=X_eval5.index\n",
    ")\n",
    "\n",
    "eval_predict_proba_tree = pd.concat(\n",
    "    [\n",
    "        eval1_predict_proba_tree,\n",
    "        eval2_predict_proba_tree,\n",
    "        eval3_predict_proba_tree,\n",
    "        eval4_predict_proba_tree,\n",
    "        eval5_predict_proba_tree,\n",
    "    ]\n",
    ").sort_index()\n",
    "\n",
    "eval1_predict_proba_lr = pd.Series(\n",
    "    lr_l[0].predict_proba(X_eval1)[:, 1], index=X_eval1.index\n",
    ")\n",
    "eval2_predict_proba_lr = pd.Series(\n",
    "    lr_l[1].predict_proba(X_eval2)[:, 1], index=X_eval2.index\n",
    ")\n",
    "eval3_predict_proba_lr = pd.Series(\n",
    "    lr_l[2].predict_proba(X_eval3)[:, 1], index=X_eval3.index\n",
    ")\n",
    "eval4_predict_proba_lr = pd.Series(\n",
    "    lr_l[3].predict_proba(X_eval4)[:, 1], index=X_eval4.index\n",
    ")\n",
    "eval5_predict_proba_lr = pd.Series(\n",
    "    lr_l[4].predict_proba(X_eval5)[:, 1], index=X_eval5.index\n",
    ")\n",
    "\n",
    "eval_predict_proba_lr = pd.concat(\n",
    "    [\n",
    "        eval1_predict_proba_lr,\n",
    "        eval2_predict_proba_lr,\n",
    "        eval3_predict_proba_lr,\n",
    "        eval4_predict_proba_lr,\n",
    "        eval5_predict_proba_lr,\n",
    "    ]\n",
    ").sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict_proba_RF = [RF_l[i].predict_proba(X_test_OE)[:, 1] for i in range(5)]\n",
    "test_predict_proba_RF = np.array(test_predict_proba_RF)\n",
    "test_predict_proba_RF = test_predict_proba_RF.mean(0)\n",
    "\n",
    "test_predict_proba_tree = [tree_l[i].predict_proba(X_test_OE)[:, 1] for i in range(5)]\n",
    "test_predict_proba_tree = np.array(test_predict_proba_tree)\n",
    "test_predict_proba_tree = test_predict_proba_tree.mean(0)\n",
    "\n",
    "test_predict_proba_lr = [lr_l[i].predict_proba(X_test_OE)[:, 1] for i in range(5)]\n",
    "test_predict_proba_lr = np.array(test_predict_proba_lr)\n",
    "test_predict_proba_lr = test_predict_proba_lr.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_space = {\n",
    "    \"thr\": hp.uniform(\"thr\", 0.4, 0.6),\n",
    "    \"weight1\": hp.uniform(\"weight1\", 0, 1),\n",
    "    \"weight2\": hp.uniform(\"weight2\", 0, 1),\n",
    "    \"weight3\": hp.uniform(\"weight3\", 0, 1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义目标函数\n",
    "def hyperopt_objective_weight(params):\n",
    "    thr = params[\"thr\"]\n",
    "    weight1 = params[\"weight1\"]\n",
    "    weight2 = params[\"weight2\"]\n",
    "    weight3 = params[\"weight3\"]\n",
    "\n",
    "    weights_sum = weight1 + weight2 + weight3\n",
    "\n",
    "    predict_proba_weight = (\n",
    "        test_predict_proba_lr * weight1\n",
    "        + test_predict_proba_tree * weight2\n",
    "        + test_predict_proba_RF * weight3\n",
    "    ) / weights_sum\n",
    "\n",
    "    res_weight = (predict_proba_weight >= thr) * 1\n",
    "\n",
    "    eval_score = accuracy_score(res_weight, y_test)\n",
    "\n",
    "    return -eval_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 优化函数\n",
    "def param_hyperopt_weight(max_evals):\n",
    "    return fmin(\n",
    "        fn=hyperopt_objective_weight,\n",
    "        space=params_space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=max_evals,\n",
    "        rstate=np.random.default_rng(17),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [01:26<00:00, 57.65trial/s, best loss: -0.8006814310051107] \n"
     ]
    }
   ],
   "source": [
    "params_best = param_hyperopt_weight(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'thr': 0.47024504133638434,\n",
       " 'weight1': 0.0012022354762377982,\n",
       " 'weight2': 0.0054382475309307995,\n",
       " 'weight3': 0.6089296721079599}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义超参数空间\n",
    "params_space = {\n",
    "    \"thr\": hp.uniform(\"thr\", 0.4, 0.6),\n",
    "    \"weight_lr1\": hp.uniform(\"weight_lr1\", 0, 1),\n",
    "    \"weight_lr2\": hp.uniform(\"weight_lr2\", 0, 1),\n",
    "    \"weight_lr3\": hp.uniform(\"weight_lr3\", 0, 1),\n",
    "    \"weight_lr4\": hp.uniform(\"weight_lr4\", 0, 1),\n",
    "    \"weight_lr5\": hp.uniform(\"weight_lr5\", 0, 1),\n",
    "    \"weight_tree1\": hp.uniform(\"weight_tree1\", 0, 1),\n",
    "    \"weight_tree2\": hp.uniform(\"weight_tree2\", 0, 1),\n",
    "    \"weight_tree3\": hp.uniform(\"weight_tree3\", 0, 1),\n",
    "    \"weight_tree4\": hp.uniform(\"weight_tree4\", 0, 1),\n",
    "    \"weight_tree5\": hp.uniform(\"weight_tree5\", 0, 1),\n",
    "    \"weight_RF1\": hp.uniform(\"weight_RF1\", 0, 1),\n",
    "    \"weight_RF2\": hp.uniform(\"weight_RF2\", 0, 1),\n",
    "    \"weight_RF3\": hp.uniform(\"weight_RF3\", 0, 1),\n",
    "    \"weight_RF4\": hp.uniform(\"weight_RF4\", 0, 1),\n",
    "    \"weight_RF5\": hp.uniform(\"weight_RF5\", 0, 1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义目标函数\n",
    "def hyperopt_objective_weight(params):\n",
    "    thr = params[\"thr\"]\n",
    "    weight_lr1 = params[\"weight_lr1\"]\n",
    "    weight_lr2 = params[\"weight_lr2\"]\n",
    "    weight_lr3 = params[\"weight_lr3\"]\n",
    "    weight_lr4 = params[\"weight_lr4\"]\n",
    "    weight_lr5 = params[\"weight_lr5\"]\n",
    "\n",
    "    weight_tree1 = params[\"weight_tree1\"]\n",
    "    weight_tree2 = params[\"weight_tree2\"]\n",
    "    weight_tree3 = params[\"weight_tree3\"]\n",
    "    weight_tree4 = params[\"weight_tree4\"]\n",
    "    weight_tree5 = params[\"weight_tree5\"]\n",
    "\n",
    "    weight_RF1 = params[\"weight_RF1\"]\n",
    "    weight_RF2 = params[\"weight_RF2\"]\n",
    "    weight_RF3 = params[\"weight_RF3\"]\n",
    "    weight_RF4 = params[\"weight_RF4\"]\n",
    "    weight_RF5 = params[\"weight_RF5\"]\n",
    "\n",
    "    eval1_predict_proba_weight = (\n",
    "        pd.Series(lr_1.predict_proba(X_eval1)[:, 1], index=X_eval1.index) * weight_lr1\n",
    "        + pd.Series(tree_1.predict_proba(X_eval1)[:, 1], index=X_eval1.index)\n",
    "        * weight_tree1\n",
    "        + pd.Series(RF_1.predict_proba(X_eval1)[:, 1], index=X_eval1.index) * weight_RF1\n",
    "    ) / (weight_lr1 + weight_tree1 + weight_RF1)\n",
    "\n",
    "    eval2_predict_proba_weight = (\n",
    "        pd.Series(lr_2.predict_proba(X_eval2)[:, 1], index=X_eval2.index) * weight_lr2\n",
    "        + pd.Series(tree_2.predict_proba(X_eval2)[:, 1], index=X_eval2.index)\n",
    "        * weight_tree2\n",
    "        + pd.Series(RF_2.predict_proba(X_eval2)[:, 1], index=X_eval2.index) * weight_RF2\n",
    "    ) / (weight_lr2 + weight_tree2 + weight_RF2)\n",
    "\n",
    "    eval3_predict_proba_weight = (\n",
    "        pd.Series(lr_3.predict_proba(X_eval3)[:, 1], index=X_eval3.index) * weight_lr3\n",
    "        + pd.Series(tree_3.predict_proba(X_eval3)[:, 1], index=X_eval3.index)\n",
    "        * weight_tree3\n",
    "        + pd.Series(RF_3.predict_proba(X_eval3)[:, 1], index=X_eval3.index) * weight_RF3\n",
    "    ) / (weight_lr3 + weight_tree3 + weight_RF3)\n",
    "\n",
    "    eval4_predict_proba_weight = (\n",
    "        pd.Series(lr_4.predict_proba(X_eval4)[:, 1], index=X_eval4.index) * weight_lr4\n",
    "        + pd.Series(tree_4.predict_proba(X_eval4)[:, 1], index=X_eval4.index)\n",
    "        * weight_tree4\n",
    "        + pd.Series(RF_4.predict_proba(X_eval4)[:, 1], index=X_eval4.index) * weight_RF4\n",
    "    ) / (weight_lr4 + weight_tree4 + weight_RF4)\n",
    "\n",
    "    eval5_predict_proba_weight = (\n",
    "        pd.Series(lr_5.predict_proba(X_eval5)[:, 1], index=X_eval5.index) * weight_lr5\n",
    "        + pd.Series(tree_5.predict_proba(X_eval5)[:, 1], index=X_eval5.index)\n",
    "        * weight_tree5\n",
    "        + pd.Series(RF_5.predict_proba(X_eval5)[:, 1], index=X_eval5.index) * weight_RF5\n",
    "    ) / (weight_lr5 + weight_tree5 + weight_RF5)\n",
    "\n",
    "    eval_predict_proba_weight = pd.concat(\n",
    "        [\n",
    "            eval1_predict_proba_weight,\n",
    "            eval2_predict_proba_weight,\n",
    "            eval3_predict_proba_weight,\n",
    "            eval4_predict_proba_weight,\n",
    "            eval5_predict_proba_weight,\n",
    "        ]\n",
    "    ).sort_index()\n",
    "\n",
    "    eval_predict = (eval_predict_proba_weight >= thr) * 1\n",
    "\n",
    "    eval_acc = accuracy_score(eval_predict, y_train)\n",
    "\n",
    "    return -eval_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_hyperopt_weight(max_evals):\n",
    "    return fmin(\n",
    "        fn=hyperopt_objective_weight,\n",
    "        space=params_space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=max_evals,\n",
    "        rstate=np.random.default_rng(2),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [10:08<00:00,  8.22trial/s, best loss: -0.8244982960999622]\n"
     ]
    }
   ],
   "source": [
    "best_params = param_hyperopt_weight(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'thr': 0.47419191141454525,\n",
       " 'weight_RF1': 0.13388324321898987,\n",
       " 'weight_RF2': 0.809291476570488,\n",
       " 'weight_RF3': 0.8180431149306414,\n",
       " 'weight_RF4': 0.449932107868016,\n",
       " 'weight_RF5': 0.7528134149351241,\n",
       " 'weight_lr1': 0.9985040011202883,\n",
       " 'weight_lr2': 0.39454849420821103,\n",
       " 'weight_lr3': 6.261034632367574e-05,\n",
       " 'weight_lr4': 0.7783270953869424,\n",
       " 'weight_lr5': 0.8593342729626122,\n",
       " 'weight_tree1': 0.2252489955409815,\n",
       " 'weight_tree2': 0.16220323052327767,\n",
       " 'weight_tree3': 0.0004439727975010005,\n",
       " 'weight_tree4': 0.09031007610111841,\n",
       " 'weight_tree5': 0.2592556306534197}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def muti_weight_test_acc(params):\n",
    "    thr = params[\"thr\"]\n",
    "    weight_lr1 = params[\"weight_lr1\"]\n",
    "    weight_lr2 = params[\"weight_lr2\"]\n",
    "    weight_lr3 = params[\"weight_lr3\"]\n",
    "    weight_lr4 = params[\"weight_lr4\"]\n",
    "    weight_lr5 = params[\"weight_lr5\"]\n",
    "\n",
    "    weight_lr_l = np.array([weight_lr1, weight_lr2, weight_lr3, weight_lr4, weight_lr5])\n",
    "    weight_lr_sum = weight_lr_l.sum()\n",
    "\n",
    "    weight_tree1 = params[\"weight_tree1\"]\n",
    "    weight_tree2 = params[\"weight_tree2\"]\n",
    "    weight_tree3 = params[\"weight_tree3\"]\n",
    "    weight_tree4 = params[\"weight_tree4\"]\n",
    "    weight_tree5 = params[\"weight_tree5\"]\n",
    "\n",
    "    weight_tree_l = np.array(\n",
    "        [weight_tree1, weight_tree2, weight_tree3, weight_tree4, weight_tree5]\n",
    "    )\n",
    "    weight_tree_sum = weight_tree_l.sum()\n",
    "\n",
    "    weight_RF1 = params[\"weight_RF1\"]\n",
    "    weight_RF2 = params[\"weight_RF2\"]\n",
    "    weight_RF3 = params[\"weight_RF3\"]\n",
    "    weight_RF4 = params[\"weight_RF4\"]\n",
    "    weight_RF5 = params[\"weight_RF5\"]\n",
    "\n",
    "    weight_RF_l = np.array([weight_RF1, weight_RF2, weight_RF3, weight_RF4, weight_RF5])\n",
    "    weight_RF_sum = weight_RF_l.sum()\n",
    "\n",
    "    test_predict_proba = (\n",
    "        lr_1.predict_proba(X_test_OE)[:, 1] * weight_lr1\n",
    "        + lr_2.predict_proba(X_test_OE)[:, 1] * weight_lr2\n",
    "        + lr_3.predict_proba(X_test_OE)[:, 1] * weight_lr3\n",
    "        + lr_4.predict_proba(X_test_OE)[:, 1] * weight_lr4\n",
    "        + lr_5.predict_proba(X_test_OE)[:, 1] * weight_lr5\n",
    "        + tree_1.predict_proba(X_test_OE)[:, 1] * weight_tree1\n",
    "        + tree_2.predict_proba(X_test_OE)[:, 1] * weight_tree2\n",
    "        + tree_3.predict_proba(X_test_OE)[:, 1] * weight_tree3\n",
    "        + tree_4.predict_proba(X_test_OE)[:, 1] * weight_tree4\n",
    "        + tree_5.predict_proba(X_test_OE)[:, 1] * weight_tree5\n",
    "        + RF_1.predict_proba(X_test_OE)[:, 1] * weight_RF1\n",
    "        + RF_2.predict_proba(X_test_OE)[:, 1] * weight_RF2\n",
    "        + RF_3.predict_proba(X_test_OE)[:, 1] * weight_RF3\n",
    "        + RF_4.predict_proba(X_test_OE)[:, 1] * weight_RF4\n",
    "        + RF_5.predict_proba(X_test_OE)[:, 1] * weight_RF5\n",
    "    ) / (weight_lr_sum + weight_tree_sum + weight_RF_sum)\n",
    "\n",
    "    test_predict = (test_predict_proba >= thr) * 1\n",
    "\n",
    "    test_acc = accuracy_score(test_predict, y_test)\n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7927314026121521"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "muti_weight_test_acc(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators_RF = [\n",
    "    (\"RF_1\", RF_1),\n",
    "    (\"RF_2\", RF_2),\n",
    "    (\"RF_3\", RF_3),\n",
    "    (\"RF_4\", RF_4),\n",
    "    (\"RF_5\", RF_5),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义超参数空间\n",
    "params_space = {\n",
    "    \"thr\": hp.uniform(\"thr\", 0.4, 0.6),\n",
    "    \"weight1\": hp.uniform(\"weight1\", 0, 1),\n",
    "    \"weight2\": hp.uniform(\"weight2\", 0, 1),\n",
    "    \"weight3\": hp.uniform(\"weight3\", 0, 1),\n",
    "    \"weight4\": hp.uniform(\"weight4\", 0, 1),\n",
    "    \"weight5\": hp.uniform(\"weight5\", 0, 1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义目标函数\n",
    "def hyperopt_objective_weight(params):\n",
    "    thr = params[\"thr\"]\n",
    "    weight1 = params[\"weight1\"]\n",
    "    weight2 = params[\"weight2\"]\n",
    "    weight3 = params[\"weight3\"]\n",
    "    weight4 = params[\"weight4\"]\n",
    "    weight5 = params[\"weight5\"]\n",
    "\n",
    "    weights = [weight1, weight2, weight3, weight4, weight5]\n",
    "\n",
    "    # 创建带阈值的平均法评估器\n",
    "    VC_weight_search = VotingClassifier_threshold(\n",
    "        estimators=estimators_RF, weights=weights, voting=\"soft\", thr=thr\n",
    "    )\n",
    "\n",
    "    # 输出验证集上的平均得分\n",
    "    val_score = cross_val_score(\n",
    "        VC_weight_search, X_train_OE, y_train, scoring=\"accuracy\", n_jobs=-1, cv=5\n",
    "    ).mean()\n",
    "\n",
    "    return -val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义优化函数\n",
    "def param_hyperopt_weight(max_evals):\n",
    "    return fmin(\n",
    "        fn=hyperopt_objective_weight,\n",
    "        space=params_space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=max_evals,\n",
    "        rstate=np.random.default_rng(2),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [05:23<00:00,  1.55trial/s, best loss: -0.8080260385310055]\n"
     ]
    }
   ],
   "source": [
    "best_params = param_hyperopt_weight(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_extract(best_params):\n",
    "    thr = best_params[\"thr\"]\n",
    "    weight1 = best_params[\"weight1\"]\n",
    "    weight2 = best_params[\"weight2\"]\n",
    "    weight3 = best_params[\"weight3\"]\n",
    "    weight4 = best_params[\"weight4\"]\n",
    "    weight5 = best_params[\"weight5\"]\n",
    "\n",
    "    weights_sum = weight1 + weight2 + weight3 + weight4 + weight5\n",
    "\n",
    "    weight1 = weight1 / weights_sum\n",
    "    weight2 = weight2 / weights_sum\n",
    "    weight3 = weight3 / weights_sum\n",
    "    weight4 = weight4 / weights_sum\n",
    "    weight5 = weight5 / weights_sum\n",
    "\n",
    "    weights = [weight1, weight2, weight3, weight4, weight5]\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_weights = weights_extract(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03915926, 0.54221843, 0.12445596, ..., 0.56028362, 0.03539781,\n",
       "       0.01897568])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_predict_proba_RF = 0\n",
    "\n",
    "for i in range(5):\n",
    "    eval_predict_proba_RF += (RF_l[i].predict_proba(X_train_OE)[:, 1]) * RF_weights[i]\n",
    "\n",
    "eval_predict_proba_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03260294, 0.30040562, 0.01954919, ..., 0.14389084, 0.52681528,\n",
       "       0.10989063])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predict_proba_RF = 0\n",
    "\n",
    "for i in range(5):\n",
    "    test_predict_proba_RF += (RF_l[i].predict_proba(X_test_OE)[:, 1]) * RF_weights[i]\n",
    "\n",
    "test_predict_proba_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators_lr = [\n",
    "    (\"lr_1\", lr_1),\n",
    "    (\"lr_2\", lr_2),\n",
    "    (\"lr_3\", lr_3),\n",
    "    (\"lr_4\", lr_4),\n",
    "    (\"lr_5\", lr_5),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义超参数空间\n",
    "params_space = {\n",
    "    \"thr\": hp.uniform(\"thr\", 0.4, 0.6),\n",
    "    \"weight1\": hp.uniform(\"weight1\", 0, 1),\n",
    "    \"weight2\": hp.uniform(\"weight2\", 0, 1),\n",
    "    \"weight3\": hp.uniform(\"weight3\", 0, 1),\n",
    "    \"weight4\": hp.uniform(\"weight4\", 0, 1),\n",
    "    \"weight5\": hp.uniform(\"weight5\", 0, 1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义目标函数\n",
    "def hyperopt_objective_weight(params):\n",
    "    thr = params[\"thr\"]\n",
    "    weight1 = params[\"weight1\"]\n",
    "    weight2 = params[\"weight2\"]\n",
    "    weight3 = params[\"weight3\"]\n",
    "    weight4 = params[\"weight4\"]\n",
    "    weight5 = params[\"weight5\"]\n",
    "\n",
    "    weights = [weight1, weight2, weight3, weight4, weight5]\n",
    "\n",
    "    # 创建带阈值的平均法评估器\n",
    "    VC_weight_search = VotingClassifier_threshold(\n",
    "        estimators=estimators_lr, weights=weights, voting=\"soft\", thr=thr\n",
    "    )\n",
    "\n",
    "    # 输出验证集上的平均得分\n",
    "    val_score = cross_val_score(\n",
    "        VC_weight_search, X_train_OE, y_train, scoring=\"accuracy\", n_jobs=15, cv=5\n",
    "    ).mean()\n",
    "\n",
    "    return -val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义优化函数\n",
    "def param_hyperopt_weight(max_evals):\n",
    "    params_best = fmin(\n",
    "        fn=hyperopt_objective_weight,\n",
    "        space=params_space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=max_evals,\n",
    "        rstate=np.random.default_rng(17),\n",
    "    )\n",
    "    return params_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [02:02<00:00,  2.45trial/s, best loss: -0.8116230899343482]\n"
     ]
    }
   ],
   "source": [
    "best_params = param_hyperopt_weight(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_weights = weights_extract(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01259023, 0.55030369, 0.14584096, ..., 0.68102564, 0.05046448,\n",
       "       0.00386074])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_predict_proba_lr = 0\n",
    "\n",
    "for i in range(5):\n",
    "    eval_predict_proba_lr += (lr_l[i].predict_proba(X_train_OE)[:, 1]) * lr_weights[i]\n",
    "\n",
    "eval_predict_proba_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04146178, 0.23631037, 0.00483358, ..., 0.13061298, 0.50063975,\n",
       "       0.06713644])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predict_proba_lr = 0\n",
    "\n",
    "for i in range(5):\n",
    "    test_predict_proba_lr += (lr_l[i].predict_proba(X_test_OE)[:, 1]) * lr_weights[i]\n",
    "\n",
    "test_predict_proba_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators_tree = [\n",
    "    (\"tree_1\", tree_1),\n",
    "    (\"tree_2\", tree_2),\n",
    "    (\"tree_3\", tree_3),\n",
    "    (\"tree_4\", tree_4),\n",
    "    (\"tree_5\", tree_5),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义超参数空间\n",
    "params_space = {\n",
    "    \"thr\": hp.uniform(\"thr\", 0.4, 0.6),\n",
    "    \"weight1\": hp.uniform(\"weight1\", 0, 1),\n",
    "    \"weight2\": hp.uniform(\"weight2\", 0, 1),\n",
    "    \"weight3\": hp.uniform(\"weight3\", 0, 1),\n",
    "    \"weight4\": hp.uniform(\"weight4\", 0, 1),\n",
    "    \"weight5\": hp.uniform(\"weight5\", 0, 1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义目标函数\n",
    "def hyperopt_objective_weight(params):\n",
    "    thr = params[\"thr\"]\n",
    "    weight1 = params[\"weight1\"]\n",
    "    weight2 = params[\"weight2\"]\n",
    "    weight3 = params[\"weight3\"]\n",
    "    weight4 = params[\"weight4\"]\n",
    "    weight5 = params[\"weight5\"]\n",
    "\n",
    "    weights = [weight1, weight2, weight3, weight4, weight5]\n",
    "\n",
    "    # 创建带阈值的平均法评估器\n",
    "    VC_weight_search = VotingClassifier_threshold(\n",
    "        estimators=estimators_tree, weights=weights, voting=\"soft\", thr=thr\n",
    "    )\n",
    "\n",
    "    # 输出验证集上的平均得分\n",
    "    val_score = cross_val_score(\n",
    "        VC_weight_search, X_train_OE, y_train, scoring=\"accuracy\", n_jobs=15, cv=5\n",
    "    ).mean()\n",
    "\n",
    "    return -val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义优化函数\n",
    "def param_hyperopt_weight(max_evals):\n",
    "    params_best = fmin(\n",
    "        fn=hyperopt_objective_weight,\n",
    "        space=params_space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=max_evals,\n",
    "        rstate=np.random.default_rng(17),\n",
    "    )\n",
    "    return params_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:14<00:00, 20.93trial/s, best loss: -0.797234167598406]\n"
     ]
    }
   ],
   "source": [
    "best_params = param_hyperopt_weight(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_weights = weights_extract(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04365352, 0.74609312, 0.16049057, ..., 0.39059284, 0.04624722,\n",
       "       0.04365352])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_predict_proba_tree = 0\n",
    "\n",
    "for i in range(5):\n",
    "    eval_predict_proba_tree += (\n",
    "        tree_l[i].predict_proba(X_train_OE)[:, 1]\n",
    "    ) * tree_weights[i]\n",
    "\n",
    "eval_predict_proba_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04365352, 0.1870317 , 0.04365352, ..., 0.1870317 , 0.45025595,\n",
       "       0.17253686])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predict_proba_tree = 0\n",
    "\n",
    "for i in range(5):\n",
    "    test_predict_proba_tree += (\n",
    "        tree_l[i].predict_proba(X_test_OE)[:, 1]\n",
    "    ) * tree_weights[i]\n",
    "\n",
    "test_predict_proba_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义超参数空间\n",
    "params_space = {\n",
    "    \"thr\": hp.uniform(\"thr\", 0.4, 0.6),\n",
    "    \"weight1\": hp.uniform(\"weight1\", 0, 1),\n",
    "    \"weight2\": hp.uniform(\"weight2\", 0, 1),\n",
    "    \"weight3\": hp.uniform(\"weight3\", 0, 1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义目标函数\n",
    "def hyperopt_objective_weight(params):\n",
    "    thr = params[\"thr\"]\n",
    "    weight1 = params[\"weight1\"]\n",
    "    weight2 = params[\"weight2\"]\n",
    "    weight3 = params[\"weight3\"]\n",
    "\n",
    "    weights_sum = weight1 + weight2 + weight3\n",
    "\n",
    "    predict_probo_weight = (\n",
    "        eval_predict_proba_lr * weight1\n",
    "        + eval_predict_proba_tree * weight2\n",
    "        + eval_predict_proba_RF * weight3\n",
    "    ) / weights_sum\n",
    "\n",
    "    res_weight = (predict_probo_weight >= thr) * 1\n",
    "\n",
    "    eval_score = accuracy_score(res_weight, y_train)\n",
    "\n",
    "    return -eval_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义优化函数\n",
    "def param_hyperopt_weight(max_evals):\n",
    "    params_best = fmin(\n",
    "        fn=hyperopt_objective_weight,\n",
    "        space=params_space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=max_evals,\n",
    "        rstate=np.random.default_rng(2),\n",
    "    )\n",
    "    return params_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [01:22<00:00, 60.70trial/s, best loss: -0.8345323741007195] \n"
     ]
    }
   ],
   "source": [
    "params_best = param_hyperopt_weight(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'thr': 0.4462784417468528,\n",
       " 'weight1': 0.020607599276297635,\n",
       " 'weight2': 0.03222821458037668,\n",
       " 'weight3': 0.8780164658743584}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_acc(params_best):\n",
    "    thr = params_best[\"thr\"]\n",
    "    weight1 = params_best[\"weight1\"]\n",
    "    weight2 = params_best[\"weight2\"]\n",
    "    weight3 = params_best[\"weight3\"]\n",
    "\n",
    "    weights_sum = weight1 + weight2 + weight3\n",
    "\n",
    "    test_predict_proba = (\n",
    "        (\n",
    "            (\n",
    "                test_predict_proba_lr * weight1\n",
    "                + test_predict_proba_tree * weight2\n",
    "                + test_predict_proba_RF * weight3\n",
    "            )\n",
    "            / weights_sum\n",
    "        )\n",
    "        >= thr\n",
    "    ) * 1\n",
    "\n",
    "    print(accuracy_score(test_predict_proba, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7938671209540034\n"
     ]
    }
   ],
   "source": [
    "test_acc(params_best)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
