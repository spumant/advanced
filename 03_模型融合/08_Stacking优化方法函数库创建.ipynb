{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基础数据科学运算库\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 可视化库\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 时间模块\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# sklearn库\n",
    "# 数据预处理\n",
    "from sklearn import preprocessing\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# 实用函数\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    recall_score,\n",
    "    precision_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 常用评估器\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# 网格搜索\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 自定义评估器支持模块\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin\n",
    "\n",
    "# 自定义模块\n",
    "from telcoFunc import *\n",
    "from manual_ensemble import *\n",
    "# 导入特征衍生模块\n",
    "import features_creation as fc\n",
    "from features_creation import *\n",
    "\n",
    "# re模块相关\n",
    "import inspect, re\n",
    "\n",
    "# 其他模块\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "from joblib import dump, load\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from hyperopt import hp, fmin, tpe, Trials\n",
    "from numpy.random import RandomState\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "tcc = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "\n",
    "# 标注连续/离散字段\n",
    "# 离散字段\n",
    "category_cols = [\n",
    "    'gender',\n",
    "    'SeniorCitizen',\n",
    "    'Partner',\n",
    "    'Dependents',\n",
    "    'PhoneService',\n",
    "    'MultipleLines',\n",
    "    'InternetService',\n",
    "    'OnlineSecurity',\n",
    "    'OnlineBackup',\n",
    "    'DeviceProtection',\n",
    "    'TechSupport',\n",
    "    'StreamingTV',\n",
    "    'StreamingMovies',\n",
    "    'Contract',\n",
    "    'PaperlessBilling',\n",
    "    'PaymentMethod',\n",
    "]\n",
    "\n",
    "# 连续字段\n",
    "numeric_cols = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "\n",
    "# 标签\n",
    "target = 'Churn'\n",
    "\n",
    "# ID列\n",
    "ID_col = 'customerID'\n",
    "\n",
    "# 验证是否划分能完全\n",
    "assert len(category_cols) + len(numeric_cols) + 2 == tcc.shape[1]\n",
    "\n",
    "# 连续字段转化\n",
    "tcc['TotalCharges'] = (\n",
    "    tcc['TotalCharges'].apply(lambda x: x if x != ' ' else np.nan).astype(float)\n",
    ")\n",
    "tcc['MonthlyCharges'] = tcc['MonthlyCharges'].astype(float)\n",
    "\n",
    "# 缺失值填补\n",
    "tcc['TotalCharges'] = tcc['TotalCharges'].fillna(0)\n",
    "\n",
    "# 标签值手动转化\n",
    "tcc['Churn'].replace(to_replace='Yes', value=1, inplace=True)\n",
    "tcc['Churn'].replace(to_replace='No', value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = tcc.drop(columns=[ID_col, target]).copy()\n",
    "labels = tcc['Churn'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集和测试集\n",
    "train, test = train_test_split(tcc, random_state=22)\n",
    "\n",
    "X_train = train.drop(columns=[ID_col, target]).copy()\n",
    "X_test = test.drop(columns=[ID_col, target]).copy()\n",
    "\n",
    "y_train = train['Churn'].copy()\n",
    "y_test = test['Churn'].copy()\n",
    "\n",
    "X_train_seq = pd.DataFrame()\n",
    "X_test_seq = pd.DataFrame()\n",
    "\n",
    "# 年份衍生\n",
    "X_train_seq['tenure_year'] = ((72 - X_train['tenure']) // 12) + 2014\n",
    "X_test_seq['tenure_year'] = ((72 - X_test['tenure']) // 12) + 2014\n",
    "\n",
    "# 月份衍生\n",
    "X_train_seq['tenure_month'] = (72 - X_train['tenure']) % 12 + 1\n",
    "X_test_seq['tenure_month'] = (72 - X_test['tenure']) % 12 + 1\n",
    "\n",
    "# 季度衍生\n",
    "X_train_seq['tenure_quarter'] = ((X_train_seq['tenure_month'] - 1) // 3) + 1\n",
    "X_test_seq['tenure_quarter'] = ((X_test_seq['tenure_month'] - 1) // 3) + 1\n",
    "\n",
    "# 独热编码\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "enc.fit(X_train_seq)\n",
    "\n",
    "seq_new = list(X_train_seq.columns)\n",
    "\n",
    "# 创建带有列名称的独热编码之后的df\n",
    "X_train_seq = pd.DataFrame(\n",
    "    enc.transform(X_train_seq).toarray(), columns=cate_colName(enc, seq_new, drop=None)\n",
    ")\n",
    "\n",
    "X_test_seq = pd.DataFrame(\n",
    "    enc.transform(X_test_seq).toarray(), columns=cate_colName(enc, seq_new, drop=None)\n",
    ")\n",
    "\n",
    "# 调整index\n",
    "X_train_seq.index = X_train.index\n",
    "X_test_seq.index = X_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ord_enc = OrdinalEncoder()\n",
    "ord_enc.fit(X_train[category_cols])\n",
    "\n",
    "X_train_OE = pd.DataFrame(\n",
    "    ord_enc.transform(X_train[category_cols]), columns=category_cols\n",
    ")\n",
    "X_train_OE.index = X_train.index\n",
    "X_train_OE = pd.concat([X_train_OE, X_train[numeric_cols]], axis=1)\n",
    "\n",
    "X_test_OE = pd.DataFrame(\n",
    "    ord_enc.transform(X_test[category_cols]), columns=category_cols\n",
    ")\n",
    "X_test_OE.index = X_test.index\n",
    "X_test_OE = pd.concat([X_test_OE, X_test[numeric_cols]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 本节新增第三方库\n",
    "from joblib import dump, load\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from hyperopt import hp, fmin, tpe\n",
    "from numpy.random import RandomState\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VotingClassifier_threshold(BaseEstimator, ClassifierMixin, TransformerMixin):\n",
    "    def __init__(self, estimators, voting=\"hard\", weights=None, thr=0.5):\n",
    "        self.estimators = estimators\n",
    "        self.voting = voting\n",
    "        self.weights = weights\n",
    "        self.thr = thr\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        VC = VotingClassifier(\n",
    "            estimators=self.estimators, voting=self.voting, weights=self.weights\n",
    "        )\n",
    "\n",
    "        VC.fit(X, y)\n",
    "        self.clf = VC\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        if self.voting == \"soft\":\n",
    "            res_proba = self.clf.predict_proba(X)\n",
    "        else:\n",
    "            res_proba = None\n",
    "        return res_proba\n",
    "\n",
    "    def predict(self, X):\n",
    "        if self.voting == \"soft\":\n",
    "            res = (self.clf.predict_proba(X)[:, 1] >= self.thr) * 1\n",
    "        else:\n",
    "            res = self.clf.predict(X)\n",
    "        return res\n",
    "\n",
    "    def score(self, X, y):\n",
    "        acc = accuracy_score(self.predict(X), y)\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化KFold评估器\n",
    "kf = KFold(n_splits=5, random_state=12, shuffle=True)\n",
    "\n",
    "# 重置训练集和测试集的index\n",
    "X_train_OE = X_train_OE.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "\n",
    "train_part_index_l = []\n",
    "eval_index_l = []\n",
    "\n",
    "for train_part_index, eval_index in kf.split(X_train_OE, y_train):\n",
    "    train_part_index_l.append(train_part_index)\n",
    "    eval_index_l.append(eval_index)\n",
    "\n",
    "# 训练集特征\n",
    "X_train1 = X_train_OE.loc[train_part_index_l[0]]\n",
    "X_train2 = X_train_OE.loc[train_part_index_l[1]]\n",
    "X_train3 = X_train_OE.loc[train_part_index_l[2]]\n",
    "X_train4 = X_train_OE.loc[train_part_index_l[3]]\n",
    "X_train5 = X_train_OE.loc[train_part_index_l[4]]\n",
    "\n",
    "# 验证集特征\n",
    "X_eval1 = X_train_OE.loc[eval_index_l[0]]\n",
    "X_eval2 = X_train_OE.loc[eval_index_l[1]]\n",
    "X_eval3 = X_train_OE.loc[eval_index_l[2]]\n",
    "X_eval4 = X_train_OE.loc[eval_index_l[3]]\n",
    "X_eval5 = X_train_OE.loc[eval_index_l[4]]\n",
    "\n",
    "# 训练集标签\n",
    "y_train1 = y_train.loc[train_part_index_l[0]]\n",
    "y_train2 = y_train.loc[train_part_index_l[1]]\n",
    "y_train3 = y_train.loc[train_part_index_l[2]]\n",
    "y_train4 = y_train.loc[train_part_index_l[3]]\n",
    "y_train5 = y_train.loc[train_part_index_l[4]]\n",
    "\n",
    "# 验证集标签\n",
    "y_eval1 = y_train.loc[eval_index_l[0]]\n",
    "y_eval2 = y_train.loc[eval_index_l[1]]\n",
    "y_eval3 = y_train.loc[eval_index_l[2]]\n",
    "y_eval4 = y_train.loc[eval_index_l[3]]\n",
    "y_eval5 = y_train.loc[eval_index_l[4]]\n",
    "\n",
    "train_set = [\n",
    "    (X_train1, y_train1),\n",
    "    (X_train2, y_train2),\n",
    "    (X_train3, y_train3),\n",
    "    (X_train4, y_train4),\n",
    "    (X_train5, y_train5),\n",
    "]\n",
    "\n",
    "eval_set = [\n",
    "    (X_eval1, y_eval1),\n",
    "    (X_eval2, y_eval2),\n",
    "    (X_eval3, y_eval3),\n",
    "    (X_eval4, y_eval4),\n",
    "    (X_eval5, y_eval5),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机森林模型组\n",
    "grid_RF_1 = load(\"./model/grid_RF_1.joblib\")\n",
    "grid_RF_2 = load(\"./model/grid_RF_2.joblib\")\n",
    "grid_RF_3 = load(\"./model/grid_RF_3.joblib\")\n",
    "grid_RF_4 = load(\"./model/grid_RF_4.joblib\")\n",
    "grid_RF_5 = load(\"./model/grid_RF_5.joblib\")\n",
    "\n",
    "RF_1 = grid_RF_1.best_estimator_\n",
    "RF_2 = grid_RF_2.best_estimator_\n",
    "RF_3 = grid_RF_3.best_estimator_\n",
    "RF_4 = grid_RF_4.best_estimator_\n",
    "RF_5 = grid_RF_5.best_estimator_\n",
    "\n",
    "RF_l = [RF_1, RF_2, RF_3, RF_4, RF_5]\n",
    "\n",
    "# 决策树模型组\n",
    "grid_tree_1 = load(\"./model/grid_tree_1.joblib\")\n",
    "grid_tree_2 = load(\"./model/grid_tree_2.joblib\")\n",
    "grid_tree_3 = load(\"./model/grid_tree_3.joblib\")\n",
    "grid_tree_4 = load(\"./model/grid_tree_4.joblib\")\n",
    "grid_tree_5 = load(\"./model/grid_tree_5.joblib\")\n",
    "\n",
    "tree_1 = grid_tree_1.best_estimator_\n",
    "tree_2 = grid_tree_2.best_estimator_\n",
    "tree_3 = grid_tree_3.best_estimator_\n",
    "tree_4 = grid_tree_4.best_estimator_\n",
    "tree_5 = grid_tree_5.best_estimator_\n",
    "\n",
    "tree_l = [tree_1, tree_2, tree_3, tree_4, tree_5]\n",
    "\n",
    "# 逻辑回归模型组\n",
    "grid_lr_1 = load(\"./model/grid_lr_1.joblib\")\n",
    "grid_lr_2 = load(\"./model/grid_lr_2.joblib\")\n",
    "grid_lr_3 = load(\"./model/grid_lr_3.joblib\")\n",
    "grid_lr_4 = load(\"./model/grid_lr_4.joblib\")\n",
    "grid_lr_5 = load(\"./model/grid_lr_5.joblib\")\n",
    "\n",
    "lr_1 = grid_lr_1.best_estimator_\n",
    "lr_2 = grid_lr_2.best_estimator_\n",
    "lr_3 = grid_lr_3.best_estimator_\n",
    "lr_4 = grid_lr_4.best_estimator_\n",
    "lr_5 = grid_lr_5.best_estimator_\n",
    "\n",
    "lr_l = [lr_1, lr_2, lr_3, lr_4, lr_5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval1_predict_proba_RF = pd.Series(\n",
    "    RF_l[0].predict_proba(X_eval1)[:, 1], index=X_eval1.index\n",
    ")\n",
    "eval2_predict_proba_RF = pd.Series(\n",
    "    RF_l[1].predict_proba(X_eval2)[:, 1], index=X_eval2.index\n",
    ")\n",
    "eval3_predict_proba_RF = pd.Series(\n",
    "    RF_l[2].predict_proba(X_eval3)[:, 1], index=X_eval3.index\n",
    ")\n",
    "eval4_predict_proba_RF = pd.Series(\n",
    "    RF_l[3].predict_proba(X_eval4)[:, 1], index=X_eval4.index\n",
    ")\n",
    "eval5_predict_proba_RF = pd.Series(\n",
    "    RF_l[4].predict_proba(X_eval5)[:, 1], index=X_eval5.index\n",
    ")\n",
    "\n",
    "eval_predict_proba_RF = pd.concat(\n",
    "    [\n",
    "        eval1_predict_proba_RF,\n",
    "        eval2_predict_proba_RF,\n",
    "        eval3_predict_proba_RF,\n",
    "        eval4_predict_proba_RF,\n",
    "        eval5_predict_proba_RF,\n",
    "    ]\n",
    ").sort_index()\n",
    "\n",
    "eval1_predict_proba_tree = pd.Series(\n",
    "    tree_l[0].predict_proba(X_eval1)[:, 1], index=X_eval1.index\n",
    ")\n",
    "eval2_predict_proba_tree = pd.Series(\n",
    "    tree_l[1].predict_proba(X_eval2)[:, 1], index=X_eval2.index\n",
    ")\n",
    "eval3_predict_proba_tree = pd.Series(\n",
    "    tree_l[2].predict_proba(X_eval3)[:, 1], index=X_eval3.index\n",
    ")\n",
    "eval4_predict_proba_tree = pd.Series(\n",
    "    tree_l[3].predict_proba(X_eval4)[:, 1], index=X_eval4.index\n",
    ")\n",
    "eval5_predict_proba_tree = pd.Series(\n",
    "    tree_l[4].predict_proba(X_eval5)[:, 1], index=X_eval5.index\n",
    ")\n",
    "\n",
    "eval_predict_proba_tree = pd.concat(\n",
    "    [\n",
    "        eval1_predict_proba_tree,\n",
    "        eval2_predict_proba_tree,\n",
    "        eval3_predict_proba_tree,\n",
    "        eval4_predict_proba_tree,\n",
    "        eval5_predict_proba_tree,\n",
    "    ]\n",
    ").sort_index()\n",
    "\n",
    "eval1_predict_proba_lr = pd.Series(\n",
    "    lr_l[0].predict_proba(X_eval1)[:, 1], index=X_eval1.index\n",
    ")\n",
    "eval2_predict_proba_lr = pd.Series(\n",
    "    lr_l[1].predict_proba(X_eval2)[:, 1], index=X_eval2.index\n",
    ")\n",
    "eval3_predict_proba_lr = pd.Series(\n",
    "    lr_l[2].predict_proba(X_eval3)[:, 1], index=X_eval3.index\n",
    ")\n",
    "eval4_predict_proba_lr = pd.Series(\n",
    "    lr_l[3].predict_proba(X_eval4)[:, 1], index=X_eval4.index\n",
    ")\n",
    "eval5_predict_proba_lr = pd.Series(\n",
    "    lr_l[4].predict_proba(X_eval5)[:, 1], index=X_eval5.index\n",
    ")\n",
    "\n",
    "eval_predict_proba_lr = pd.concat(\n",
    "    [\n",
    "        eval1_predict_proba_lr,\n",
    "        eval2_predict_proba_lr,\n",
    "        eval3_predict_proba_lr,\n",
    "        eval4_predict_proba_lr,\n",
    "        eval5_predict_proba_lr,\n",
    "    ]\n",
    ").sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict_proba_RF = []\n",
    "\n",
    "for i in range(5):\n",
    "    test_predict_proba_RF.append(RF_l[i].predict_proba(X_test_OE)[:, 1])\n",
    "\n",
    "test_predict_proba_RF = np.array(test_predict_proba_RF)\n",
    "test_predict_proba_RF = test_predict_proba_RF.mean(0)\n",
    "\n",
    "test_predict_proba_tree = []\n",
    "\n",
    "for i in range(5):\n",
    "    test_predict_proba_tree.append(tree_l[i].predict_proba(X_test_OE)[:, 1])\n",
    "\n",
    "test_predict_proba_tree = np.array(test_predict_proba_tree)\n",
    "test_predict_proba_tree = test_predict_proba_tree.mean(0)\n",
    "\n",
    "test_predict_proba_lr = []\n",
    "\n",
    "for i in range(5):\n",
    "    test_predict_proba_lr.append(lr_l[i].predict_proba(X_test_OE)[:, 1])\n",
    "\n",
    "test_predict_proba_lr = np.array(test_predict_proba_lr)\n",
    "test_predict_proba_lr = test_predict_proba_lr.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import manual_ensemble as me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mType:\u001b[0m        module\n",
      "\u001b[1;31mString form:\u001b[0m <module 'manual_ensemble' from 'f:\\\\study\\\\python\\\\code6\\\\More advanced machine learning\\\\03_模型融合\\\\manual_ensemble.py'>\n",
      "\u001b[1;31mFile:\u001b[0m        f:\\study\\python\\code6\\more advanced machine learning\\03_模型融合\\manual_ensemble.py\n",
      "\u001b[1;31mDocstring:\u001b[0m   自动模型融合模块"
     ]
    }
   ],
   "source": [
    "me?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_params_space = {\n",
    "    \"tree_max_depth\": hp.choice(\"tree_max_depth\", np.arange(2, 20).tolist()),\n",
    "    \"tree_min_samples_split\": hp.choice(\n",
    "        \"tree_min_samples_split\", np.arange(2, 15).tolist()\n",
    "    ),\n",
    "    \"tree_min_samples_leaf\": hp.choice(\n",
    "        \"tree_min_samples_leaf\", np.arange(1, 15).tolist()\n",
    "    ),\n",
    "    \"tree_max_leaf_nodes\": hp.choice(\"tree_max_leaf_nodes\", np.arange(2, 51).tolist()),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperopt_tree(params, train=True):\n",
    "    # 读取参数\n",
    "    if train == True:\n",
    "        max_depth = params[\"tree_max_depth\"]\n",
    "        min_samples_split = params[\"tree_min_samples_split\"]\n",
    "        min_samples_leaf = params[\"tree_min_samples_leaf\"]\n",
    "        max_leaf_nodes = params[\"tree_max_leaf_nodes\"]\n",
    "    else:\n",
    "        max_depth = params[\"tree_max_depth\"] + 2\n",
    "        min_samples_split = params[\"tree_min_samples_split\"] + 2\n",
    "        min_samples_leaf = params[\"tree_min_samples_leaf\"] + 1\n",
    "        max_leaf_nodes = params[\"tree_max_leaf_nodes\"] + 2\n",
    "    tree = DecisionTreeClassifier(\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        max_leaf_nodes=max_leaf_nodes,\n",
    "    )\n",
    "\n",
    "    if train == True:\n",
    "        res = -cross_val_score(tree, X_train_OE, y_train).mean()\n",
    "    else:\n",
    "        res = tree.fit(X_train_OE, y_train)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_hyperopt_tree(max_evals):\n",
    "    return fmin(\n",
    "        fn=hyperopt_tree,\n",
    "        space=tree_params_space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=max_evals,\n",
    "        rstate=np.random.default_rng(9),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:39<00:00, 25.06trial/s, best loss: -0.7962873770820791]\n"
     ]
    }
   ],
   "source": [
    "tree_params_best = param_hyperopt_tree(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tree_max_depth': 3,\n",
       " 'tree_max_leaf_nodes': 44,\n",
       " 'tree_min_samples_leaf': 10,\n",
       " 'tree_min_samples_split': 3}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_params_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=5, max_leaf_nodes=46, min_samples_leaf=11,\n",
       "                       min_samples_split=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=5, max_leaf_nodes=46, min_samples_leaf=11,\n",
       "                       min_samples_split=5)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=5, max_leaf_nodes=46, min_samples_leaf=11,\n",
       "                       min_samples_split=5)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperopt_tree(tree_params_best, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = hyperopt_tree(tree_params_best, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7773992049971608"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "而训练状态和测试状态的重要区别，就在于参数的导入。对于hyperOPT来说，hp.choice的搜索结果其实是原始参数取值列表的索引值，例如max_depth：3，其实代表的是原始参数空间中'tree_max_depth': hp.choice('RF_max_depth', np.arange(2, 20).tolist())的第3个值，也就是2+3=5:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因此目标函数在定义train=False的代码时，对于整数列表的数值提取，只需要用得到的索引值+列表初始值即可。再比如max_leaf_nodes的最佳值索引是27,则真实值为2+27=29。当然，对于字符串列表，则需要直接把字符串完整列表带入进行索引。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tree_cascade(BaseEstimator, ClassifierMixin, TransformerMixin):\n",
    "    def __init__(self, tree_params_space, max_evals=1000):\n",
    "        self.tree_params_space = tree_params_space\n",
    "        self.max_evals = max_evals\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        def hyperopt_tree(params, train=True):\n",
    "            # 读取参数\n",
    "            if train == True:\n",
    "                max_depth = params[\"tree_max_depth\"]\n",
    "                min_samples_split = params[\"tree_min_samples_split\"]\n",
    "                min_samples_leaf = params[\"tree_min_samples_leaf\"]\n",
    "                max_leaf_nodes = params[\"tree_max_leaf_nodes\"]\n",
    "            else:\n",
    "                max_depth = params[\"tree_max_depth\"] + 2\n",
    "                min_samples_split = params[\"tree_min_samples_split\"] + 2\n",
    "                min_samples_leaf = params[\"tree_min_samples_leaf\"] + 1\n",
    "                max_leaf_nodes = params[\"tree_max_leaf_nodes\"] + 2\n",
    "\n",
    "            # 实例化模型\n",
    "            tree = DecisionTreeClassifier(\n",
    "                max_depth=max_depth,\n",
    "                min_samples_split=min_samples_split,\n",
    "                min_samples_leaf=min_samples_leaf,\n",
    "                max_leaf_nodes=max_leaf_nodes,\n",
    "                random_state=12,\n",
    "            )\n",
    "\n",
    "            if train == True:\n",
    "                res = -cross_val_score(tree, X, y).mean()\n",
    "            else:\n",
    "                res = tree.fit(X, y)\n",
    "\n",
    "            return res\n",
    "\n",
    "        def param_hyperopt_tree(max_evals):\n",
    "            params_best = fmin(\n",
    "                fn=hyperopt_tree,\n",
    "                space=self.tree_params_space,\n",
    "                algo=tpe.suggest,\n",
    "                max_evals=max_evals,\n",
    "                rstate=np.random.default_rng(9),\n",
    "            )\n",
    "\n",
    "            return params_best\n",
    "\n",
    "        tree_params_best = param_hyperopt_tree(self.max_evals)\n",
    "        self.clf = hyperopt_tree(tree_params_best, train=False)\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.clf.predict_proba(X)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.clf.predict(X)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return self.clf.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_hyper = tree_cascade(tree_params_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:40<00:00, 24.83trial/s, best loss: -0.7962873770820791]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>tree_cascade(tree_params_space={&#x27;tree_max_depth&#x27;: &lt;hyperopt.pyll.base.Apply object at 0x0000013B0437EF10&gt;,\n",
       "                                &#x27;tree_max_leaf_nodes&#x27;: &lt;hyperopt.pyll.base.Apply object at 0x0000013B089CB5E0&gt;,\n",
       "                                &#x27;tree_min_samples_leaf&#x27;: &lt;hyperopt.pyll.base.Apply object at 0x0000013B08A87F10&gt;,\n",
       "                                &#x27;tree_min_samples_split&#x27;: &lt;hyperopt.pyll.base.Apply object at 0x0000013B08813B50&gt;})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">tree_cascade</label><div class=\"sk-toggleable__content\"><pre>tree_cascade(tree_params_space={&#x27;tree_max_depth&#x27;: &lt;hyperopt.pyll.base.Apply object at 0x0000013B0437EF10&gt;,\n",
       "                                &#x27;tree_max_leaf_nodes&#x27;: &lt;hyperopt.pyll.base.Apply object at 0x0000013B089CB5E0&gt;,\n",
       "                                &#x27;tree_min_samples_leaf&#x27;: &lt;hyperopt.pyll.base.Apply object at 0x0000013B08A87F10&gt;,\n",
       "                                &#x27;tree_min_samples_split&#x27;: &lt;hyperopt.pyll.base.Apply object at 0x0000013B08813B50&gt;})</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "tree_cascade(tree_params_space={'tree_max_depth': <hyperopt.pyll.base.Apply object at 0x0000013B0437EF10>,\n",
       "                                'tree_max_leaf_nodes': <hyperopt.pyll.base.Apply object at 0x0000013B089CB5E0>,\n",
       "                                'tree_min_samples_leaf': <hyperopt.pyll.base.Apply object at 0x0000013B08A87F10>,\n",
       "                                'tree_min_samples_split': <hyperopt.pyll.base.Apply object at 0x0000013B08813B50>})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_hyper.fit(X_train_OE, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_hyper.predict(X_test_OE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7768313458262351"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_hyper.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:26<00:00, 23.13trial/s, best loss: -0.7962873770820791]\n"
     ]
    }
   ],
   "source": [
    "tree_hyper = tree_cascade(tree_params_space, max_evals=2000).fit(X_train_OE, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7768313458262351"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_hyper.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_params_space = {\n",
    "    \"RF_min_samples_leaf\": hp.choice(\"RF_min_samples_leaf\", np.arange(1, 20).tolist()),\n",
    "    \"RF_min_samples_split\": hp.choice(\n",
    "        \"RF_min_samples_split\", np.arange(2, 20).tolist()\n",
    "    ),\n",
    "    \"RF_max_depth\": hp.choice(\"RF_max_depth\", np.arange(2, 20).tolist()),\n",
    "    \"RF_max_leaf_nodes\": hp.choice(\"RF_max_leaf_nodes\", np.arange(20, 200).tolist()),\n",
    "    \"RF_n_estimators\": hp.choice(\"RF_n_estimators\", np.arange(20, 200).tolist()),\n",
    "    \"RF_max_samples\": hp.uniform(\"RF_max_samples\", 0.2, 0.8),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RF_cascade(BaseEstimator, ClassifierMixin, TransformerMixin):\n",
    "    def __init__(self, RF_params_space, max_evals=500):\n",
    "        self.RF_params_space = RF_params_space\n",
    "        self.max_evals = max_evals\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        def hyperopt_RF(params, train=True):\n",
    "            # 读取参数\n",
    "            if train == True:\n",
    "                min_samples_leaf = params[\"RF_min_samples_leaf\"]\n",
    "                min_samples_split = params[\"RF_min_samples_split\"]\n",
    "                max_depth = params[\"RF_max_depth\"]\n",
    "                max_leaf_nodes = params[\"RF_max_leaf_nodes\"]\n",
    "                n_estimators = params[\"RF_n_estimators\"]\n",
    "                max_samples = params[\"RF_max_samples\"]\n",
    "            else:\n",
    "                min_samples_leaf = params[\"RF_min_samples_leaf\"] + 1\n",
    "                min_samples_split = params[\"RF_min_samples_split\"] + 2\n",
    "                max_depth = params[\"RF_max_depth\"] + 2\n",
    "                max_leaf_nodes = params[\"RF_max_leaf_nodes\"] + 20\n",
    "                n_estimators = params[\"RF_n_estimators\"] + 20\n",
    "                max_samples = params[\"RF_max_samples\"]\n",
    "            # 实例化模型\n",
    "            RF = RandomForestClassifier(\n",
    "                min_samples_leaf=min_samples_leaf,\n",
    "                min_samples_split=min_samples_split,\n",
    "                max_depth=max_depth,\n",
    "                max_leaf_nodes=max_leaf_nodes,\n",
    "                n_estimators=n_estimators,\n",
    "                max_samples=max_samples,\n",
    "            )\n",
    "            if train == True:\n",
    "                res = -cross_val_score(RF, X, y).mean()\n",
    "            else:\n",
    "                res = RF.fit(X, y)\n",
    "\n",
    "            return res\n",
    "\n",
    "        def param_hyperopt_RF(max_evals):\n",
    "            params_best = fmin(\n",
    "                fn=hyperopt_RF,\n",
    "                space=self.RF_params_space,\n",
    "                algo=tpe.suggest,\n",
    "                max_evals=max_evals,\n",
    "            )\n",
    "\n",
    "            return params_best\n",
    "\n",
    "        RF_params_best = param_hyperopt_RF(self.max_evals)\n",
    "        self.clf = hyperopt_RF(RF_params_best, train=False)\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.clf.predict_proba(X)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.clf.predict(X)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return self.clf.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [06:14<00:00,  1.34trial/s, best loss: -0.8099199779249447]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RF_cascade(RF_params_space={&#x27;RF_max_depth&#x27;: &lt;hyperopt.pyll.base.Apply object at 0x0000013B0439B820&gt;,\n",
       "                            &#x27;RF_max_leaf_nodes&#x27;: &lt;hyperopt.pyll.base.Apply object at 0x0000013B043B79A0&gt;,\n",
       "                            &#x27;RF_max_samples&#x27;: &lt;hyperopt.pyll.base.Apply object at 0x0000013B08D855E0&gt;,\n",
       "                            &#x27;RF_min_samples_leaf&#x27;: &lt;hyperopt.pyll.base.Apply object at 0x0000013B0442B5B0&gt;,\n",
       "                            &#x27;RF_min_samples_split&#x27;: &lt;hyperopt.pyll.base.Apply object at 0x0000013B0442B460&gt;,\n",
       "                            &#x27;RF_n_estimators&#x27;: &lt;hyperopt.pyll.base.Apply object at 0x0000013B08A085B0&gt;})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RF_cascade</label><div class=\"sk-toggleable__content\"><pre>RF_cascade(RF_params_space={&#x27;RF_max_depth&#x27;: &lt;hyperopt.pyll.base.Apply object at 0x0000013B0439B820&gt;,\n",
       "                            &#x27;RF_max_leaf_nodes&#x27;: &lt;hyperopt.pyll.base.Apply object at 0x0000013B043B79A0&gt;,\n",
       "                            &#x27;RF_max_samples&#x27;: &lt;hyperopt.pyll.base.Apply object at 0x0000013B08D855E0&gt;,\n",
       "                            &#x27;RF_min_samples_leaf&#x27;: &lt;hyperopt.pyll.base.Apply object at 0x0000013B0442B5B0&gt;,\n",
       "                            &#x27;RF_min_samples_split&#x27;: &lt;hyperopt.pyll.base.Apply object at 0x0000013B0442B460&gt;,\n",
       "                            &#x27;RF_n_estimators&#x27;: &lt;hyperopt.pyll.base.Apply object at 0x0000013B08A085B0&gt;})</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RF_cascade(RF_params_space={'RF_max_depth': <hyperopt.pyll.base.Apply object at 0x0000013B0439B820>,\n",
       "                            'RF_max_leaf_nodes': <hyperopt.pyll.base.Apply object at 0x0000013B043B79A0>,\n",
       "                            'RF_max_samples': <hyperopt.pyll.base.Apply object at 0x0000013B08D855E0>,\n",
       "                            'RF_min_samples_leaf': <hyperopt.pyll.base.Apply object at 0x0000013B0442B5B0>,\n",
       "                            'RF_min_samples_split': <hyperopt.pyll.base.Apply object at 0x0000013B0442B460>,\n",
       "                            'RF_n_estimators': <hyperopt.pyll.base.Apply object at 0x0000013B08A085B0>})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_hyper = RF_cascade(RF_params_space)\n",
    "RF_hyper.fit(X_train_OE, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7893242475865985"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_hyper.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [11:37<00:00,  1.43trial/s, best loss: -0.8099194403830164]\n"
     ]
    }
   ],
   "source": [
    "RF_hyper = RF_cascade(RF_params_space, max_evals=1000).fit(X_train_OE, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7842135150482681"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_hyper.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_params_space = {\n",
    "    \"lr_C\": hp.uniform(\"lr_C\", 0, 1),\n",
    "    \"lr_penalty\": hp.choice(\"lr_penalty\", [\"l1\", \"l2\"]),\n",
    "    \"lr_thr\": hp.uniform(\"lr_thr\", 0, 1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lr_cascade(BaseEstimator, ClassifierMixin, TransformerMixin):\n",
    "    def __init__(self, lr_params_space, max_evals=20):\n",
    "        self.lr_params_space = lr_params_space\n",
    "        self.max_evals = max_evals\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        def hyperopt_lr(params, train=True):\n",
    "            # 读取参数\n",
    "            if train == True:\n",
    "                C = params[\"lr_C\"]\n",
    "                penalty = params[\"lr_penalty\"]\n",
    "                thr = params[\"lr_thr\"]\n",
    "            else:\n",
    "                C = params[\"lr_C\"]\n",
    "                penalty = [\"l1\", \"l2\"][params[\"lr_penalty\"]]\n",
    "                thr = params[\"lr_thr\"]\n",
    "            # 实例化模型\n",
    "            lr = logit_threshold(\n",
    "                C=C, thr=thr, penalty=penalty, solver=\"saga\", max_iter=int(1e6)\n",
    "            )\n",
    "\n",
    "            if train == True:\n",
    "                res = -cross_val_score(lr, X, y).mean()\n",
    "            else:\n",
    "                res = lr.fit(X, y)\n",
    "\n",
    "            return res\n",
    "\n",
    "        def param_hyperopt_lr(max_evals):\n",
    "            params_best = fmin(\n",
    "                fn=hyperopt_lr,\n",
    "                space=self.lr_params_space,\n",
    "                algo=tpe.suggest,\n",
    "                max_evals=max_evals,\n",
    "                rstate=np.random.default_rng(9),\n",
    "            )\n",
    "\n",
    "            return params_best\n",
    "\n",
    "        lr_params_best = param_hyperopt_lr(self.max_evals)\n",
    "        self.clf = hyperopt_lr(lr_params_best, train=False)\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.clf.predict_proba(X)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.clf.predict(X)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return self.clf.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:54<00:00,  5.74s/trial, best loss: -0.7890945285398928]\n"
     ]
    }
   ],
   "source": [
    "lr_hyper = lr_cascade(lr_params_space).fit(X_train_OE, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7717206132879046"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_hyper.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_hyper = lr_cascade(lr_params_space)\n",
    "tree_hyper = tree_cascade(tree_params_space)\n",
    "RF_hyper = RF_cascade(RF_params_space)\n",
    "\n",
    "estimators = [('lr', lr_hyper), ('tree', tree_hyper), ('rf', RF_hyper)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:44<00:00,  5.20s/trial, best loss: -0.7874556213017752]\n",
      "100%|██████████| 20/20 [01:42<00:00,  5.11s/trial, best loss: -0.7886390532544378]\n",
      "100%|██████████| 20/20 [01:40<00:00,  5.02s/trial, best loss: -0.7884507672723713]\n",
      "100%|██████████| 20/20 [01:41<00:00,  5.10s/trial, best loss: -0.792946969379048] \n",
      "100%|██████████| 20/20 [01:39<00:00,  4.97s/trial, best loss: -0.7865567166058165]\n",
      "100%|██████████| 1000/1000 [00:34<00:00, 28.90trial/s, best loss: -0.7983431952662723]\n",
      "100%|██████████| 1000/1000 [00:33<00:00, 29.54trial/s, best loss: -0.7919526627218935]\n",
      "100%|██████████| 1000/1000 [00:33<00:00, 29.66trial/s, best loss: -0.7986249248115043]\n",
      "100%|██████████| 1000/1000 [00:35<00:00, 28.43trial/s, best loss: -0.8033578133087135]\n",
      "100%|██████████| 1000/1000 [00:35<00:00, 28.12trial/s, best loss: -0.7905781470756921]\n",
      "100%|██████████| 500/500 [04:42<00:00,  1.77trial/s, best loss: -0.8049704142011833]\n",
      "100%|██████████| 500/500 [04:37<00:00,  1.80trial/s, best loss: -0.8111242603550297]\n",
      "100%|██████████| 500/500 [05:07<00:00,  1.63trial/s, best loss: -0.8104550477709234]\n",
      "100%|██████████| 500/500 [05:18<00:00,  1.57trial/s, best loss: -0.8102200400072741]\n",
      "100%|██████████| 500/500 [04:55<00:00,  1.69trial/s, best loss: -0.8097447088281786]\n"
     ]
    }
   ],
   "source": [
    "train_oof, test_predict = train_cross(\n",
    "    X_train_OE, y_train, X_test_OE, estimators=estimators\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8065126845891708, 0.787052810902896)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 设置超参数空间\n",
    "logistic_param = [\n",
    "    {\n",
    "        \"thr\": np.arange(0.1, 1, 0.1).tolist(),\n",
    "        \"penalty\": [\"l1\"],\n",
    "        \"C\": np.arange(0.1, 1.1, 0.1).tolist(),\n",
    "        \"solver\": [\"saga\"],\n",
    "    },\n",
    "    {\n",
    "        \"thr\": np.arange(0.1, 1, 0.1).tolist(),\n",
    "        \"penalty\": [\"l2\"],\n",
    "        \"C\": np.arange(0.1, 1.1, 0.1).tolist(),\n",
    "        \"solver\": [\"lbfgs\", \"newton-cg\", \"sag\", \"saga\"],\n",
    "    },\n",
    "]\n",
    "\n",
    "# 实例化相关评估器\n",
    "logistic_final = logit_threshold(max_iter=int(1e6))\n",
    "\n",
    "# 执行网格搜索\n",
    "lfg = GridSearchCV(\n",
    "    estimator=logistic_final, param_grid=logistic_param, scoring=\"accuracy\", n_jobs=15\n",
    ").fit(train_oof.iloc[:, :3], y_train)\n",
    "\n",
    "lfg.score(train_oof.iloc[:, :3], y_train), lfg.score(test_predict, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_model_opt(final_model_l, param_space_l, X, y, test_predict):\n",
    "    \"\"\"\n",
    "    Stacking元学习器自动优化与预测函数\n",
    "\n",
    "    :param final_model_l: 备选元学习器组成的列表\n",
    "    :param param_space_l: 备选元学习器各自超参数搜索空间组成的列表\n",
    "    :param X: oof_train训练集特征\n",
    "    :param y: oof_train训练集标签\n",
    "    :param test_predict: 一级评估器输出的测试集预测结果\n",
    "\n",
    "    :return：多组元学习器在oof_train上的最佳评分，以及最佳元学习器在test_predict上的预测结果\n",
    "    \"\"\"\n",
    "\n",
    "    # 不同组元学习器结果存储列表\n",
    "    # res_l用于存储模型在训练集上的评分\n",
    "    res_l = np.zeros(len(final_model_l)).tolist()\n",
    "    # test_predict_l用于存储模型在测试集test_predict上的预测结果\n",
    "    test_predict_l = np.zeros(len(final_model_l)).tolist()\n",
    "\n",
    "    for i, model in enumerate(final_model_l):\n",
    "        # 输出元学习器单模预测结果\n",
    "        # 执行网格搜索\n",
    "        model_grid = GridSearchCV(\n",
    "            estimator=model, param_grid=param_space_l[i], scoring=\"accuracy\", n_jobs=15\n",
    "        )\n",
    "        model_grid.fit(X, y)\n",
    "        # 记录单模最佳模型，方便后续作为Bagging的基础评估器\n",
    "        res1_best_model = model_grid.best_estimator_\n",
    "        # 测试在训练oof数据集上的准确率\n",
    "        res1 = model_grid.score(X, y)\n",
    "        # 输出单模在test_predict上的预测结果\n",
    "        res1_test_predict = model_grid.predict_proba(test_predict)[:, 1]\n",
    "\n",
    "        # 输出元学习器交叉训练预测结果\n",
    "        res2_temp = np.zeros(y.shape[0])\n",
    "        res2_test_predict = np.zeros(test_predict.shape[0])\n",
    "        # 交叉训练过程附带网格搜索以提升精度\n",
    "        folds = RepeatedKFold(n_splits=5, n_repeats=2, random_state=12)\n",
    "        for trn_idx, val_idx in folds.split(X, y):\n",
    "            model_grid = GridSearchCV(\n",
    "                estimator=model,\n",
    "                param_grid=param_space_l[i],\n",
    "                scoring=\"accuracy\",\n",
    "                n_jobs=15,\n",
    "            )\n",
    "            model_grid.fit(X.loc[trn_idx], y.loc[trn_idx])\n",
    "            res2_temp += model_grid.predict_proba(X)[:, 1] / 10\n",
    "            # 记录测试集上的预测结果\n",
    "            res2_test_predict += model_grid.predict_proba(test_predict)[:, 1] / 10\n",
    "        # 交叉训练模型组评分\n",
    "        res2 = accuracy_score((res2_temp >= 0.5) * 1, y)\n",
    "\n",
    "        # 元学习器的Bagging过程\n",
    "        bagging_param_space = {\n",
    "            \"n_estimators\": range(10, 21),\n",
    "            \"max_samples\": np.arange(0.1, 1.1, 0.1).tolist(),\n",
    "        }\n",
    "\n",
    "        bagging_final = BaggingClassifier(res1_best_model)\n",
    "        BG = GridSearchCV(bagging_final, bagging_param_space, n_jobs=15).fit(X, y)\n",
    "        # Bagging元学习器评分\n",
    "        res3 = BG.score(X, y)\n",
    "        # Bagging元学习器在测试集上评分\n",
    "        res3_test_predict = BG.predict_proba(test_predict)[:, 1]\n",
    "\n",
    "        # 三组模型评分组成列表\n",
    "        res_l_temp = [res1, res2, res3]\n",
    "        # 三组模型在测试集上预测结果组成列表\n",
    "        test_predict_l_temp = [res1_test_predict, res2_test_predict, res3_test_predict]\n",
    "        # 挑选评分最高模型\n",
    "        best_res = np.max(res_l_temp)\n",
    "        # 挑选评分最高模型输出的测试集概率预测结果\n",
    "        best_test_predict = test_predict_l_temp[np.argmax(res_l_temp)]\n",
    "        # 将最佳模型写入res_l对应位置\n",
    "        res_l[i] = best_res\n",
    "        # 将最佳模型在测试集上的评分写入test_predict_l\n",
    "        test_predict_l[i] = best_test_predict\n",
    "\n",
    "    # 再从res_l中选取训练集上最佳评分\n",
    "    best_res_final = np.max(res_l)\n",
    "    # 根据训练集上的最佳评分，选取挑选最佳测试集预测结果\n",
    "    best_test_predict_final = test_predict_l[np.argmax(res_l)]\n",
    "\n",
    "    return best_res_final, best_test_predict_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = logit_threshold()\n",
    "tree = DecisionTreeClassifier()\n",
    "final_model_l = [lr, tree]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_final_param = [\n",
    "    {\n",
    "        \"thr\": np.arange(0.1, 1.1, 0.1).tolist(),\n",
    "        \"penalty\": [\"l1\"],\n",
    "        \"C\": np.arange(0.1, 1.1, 0.1).tolist(),\n",
    "        \"solver\": [\"saga\"],\n",
    "    },\n",
    "    {\n",
    "        \"thr\": np.arange(0.1, 1.1, 0.1).tolist(),\n",
    "        \"penalty\": [\"l2\"],\n",
    "        \"C\": np.arange(0.1, 1.1, 0.1).tolist(),\n",
    "        \"solver\": [\"lbfgs\", \"newton-cg\", \"sag\", \"saga\"],\n",
    "    },\n",
    "]\n",
    "\n",
    "tree_final_param = {\n",
    "    \"max_depth\": np.arange(2, 16, 1).tolist(),\n",
    "    \"min_samples_split\": np.arange(2, 5, 1).tolist(),\n",
    "    \"min_samples_leaf\": np.arange(1, 4, 1).tolist(),\n",
    "    \"max_leaf_nodes\": np.arange(6, 30, 1).tolist(),\n",
    "}\n",
    "\n",
    "param_space_l = [lr_final_param, tree_final_param]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_res_final, best_test_predict_final = final_model_opt(\n",
    "    final_model_l, param_space_l, train_oof.iloc[:, :3], y_train, test_predict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7921635434412265"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score((best_test_predict_final >= 0.5) * 1, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_hyper = lr_cascade(lr_params_space, max_evals=50)\n",
    "tree_hyper = tree_cascade(tree_params_space)\n",
    "RF_hyper = RF_cascade(RF_params_space, max_evals=1000)\n",
    "\n",
    "estimators = [(\"lr\", lr_hyper), (\"tree\", tree_hyper), (\"rf\", RF_hyper)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_oof, test_predict = train_cross(\n",
    "    X_train_OE, y_train, X_test_OE, estimators=estimators\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = logit_threshold()\n",
    "tree = DecisionTreeClassifier()\n",
    "final_model_l = [lr, tree]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_res_final, best_test_predict_final = final_model_opt(\n",
    "    final_model_l, param_space_l, train_oof.iloc[:, :3], y_train, test_predict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score((best_test_predict_final >= 0.5) * 1, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
