{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基础数据科学运算库\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 可视化库\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 时间模块\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# sklearn库\n",
    "# 数据预处理\n",
    "from sklearn import preprocessing\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# 实用函数\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    recall_score,\n",
    "    precision_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 常用评估器\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "# 网格搜索\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 自定义评估器支持模块\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin\n",
    "\n",
    "# 自定义模块\n",
    "from telcoFunc import *\n",
    "\n",
    "# 导入特征衍生模块\n",
    "import features_creation as fc\n",
    "from features_creation import *\n",
    "\n",
    "# re模块相关\n",
    "import inspect, re\n",
    "\n",
    "# 其他模块\n",
    "from tqdm import tqdm\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "tcc = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "\n",
    "# 标注连续/离散字段\n",
    "# 离散字段\n",
    "category_cols = [\n",
    "    'gender',\n",
    "    'SeniorCitizen',\n",
    "    'Partner',\n",
    "    'Dependents',\n",
    "    'PhoneService',\n",
    "    'MultipleLines',\n",
    "    'InternetService',\n",
    "    'OnlineSecurity',\n",
    "    'OnlineBackup',\n",
    "    'DeviceProtection',\n",
    "    'TechSupport',\n",
    "    'StreamingTV',\n",
    "    'StreamingMovies',\n",
    "    'Contract',\n",
    "    'PaperlessBilling',\n",
    "    'PaymentMethod',\n",
    "]\n",
    "\n",
    "# 连续字段\n",
    "numeric_cols = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "\n",
    "# 标签\n",
    "target = 'Churn'\n",
    "\n",
    "# ID列\n",
    "ID_col = 'customerID'\n",
    "\n",
    "# 验证是否划分能完全\n",
    "assert len(category_cols) + len(numeric_cols) + 2 == tcc.shape[1]\n",
    "\n",
    "# 连续字段转化\n",
    "tcc['TotalCharges'] = (\n",
    "    tcc['TotalCharges'].apply(lambda x: x if x != ' ' else np.nan).astype(float)\n",
    ")\n",
    "tcc['MonthlyCharges'] = tcc['MonthlyCharges'].astype(float)\n",
    "\n",
    "# 缺失值填补\n",
    "tcc['TotalCharges'] = tcc['TotalCharges'].fillna(0)\n",
    "\n",
    "# 标签值手动转化\n",
    "tcc['Churn'].replace(to_replace='Yes', value=1, inplace=True)\n",
    "tcc['Churn'].replace(to_replace='No', value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = tcc.drop(columns=[ID_col, target]).copy()\n",
    "labels = tcc['Churn'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集和测试集\n",
    "train, test = train_test_split(tcc, random_state=22)\n",
    "\n",
    "X_train = train.drop(columns=[ID_col, target]).copy()\n",
    "X_test = test.drop(columns=[ID_col, target]).copy()\n",
    "\n",
    "y_train = train['Churn'].copy()\n",
    "y_test = test['Churn'].copy()\n",
    "\n",
    "X_train_seq = pd.DataFrame()\n",
    "X_test_seq = pd.DataFrame()\n",
    "\n",
    "# 年份衍生\n",
    "X_train_seq['tenure_year'] = ((72 - X_train['tenure']) // 12) + 2014\n",
    "X_test_seq['tenure_year'] = ((72 - X_test['tenure']) // 12) + 2014\n",
    "\n",
    "# 月份衍生\n",
    "X_train_seq['tenure_month'] = (72 - X_train['tenure']) % 12 + 1\n",
    "X_test_seq['tenure_month'] = (72 - X_test['tenure']) % 12 + 1\n",
    "\n",
    "# 季度衍生\n",
    "X_train_seq['tenure_quarter'] = ((X_train_seq['tenure_month'] - 1) // 3) + 1\n",
    "X_test_seq['tenure_quarter'] = ((X_test_seq['tenure_month'] - 1) // 3) + 1\n",
    "\n",
    "# 独热编码\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "enc.fit(X_train_seq)\n",
    "\n",
    "seq_new = list(X_train_seq.columns)\n",
    "\n",
    "# 创建带有列名称的独热编码之后的df\n",
    "X_train_seq = pd.DataFrame(\n",
    "    enc.transform(X_train_seq).toarray(), columns=cate_colName(enc, seq_new, drop=None)\n",
    ")\n",
    "\n",
    "X_test_seq = pd.DataFrame(\n",
    "    enc.transform(X_test_seq).toarray(), columns=cate_colName(enc, seq_new, drop=None)\n",
    ")\n",
    "\n",
    "# 调整index\n",
    "X_train_seq.index = X_train.index\n",
    "X_test_seq.index = X_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ord_enc = OrdinalEncoder()\n",
    "ord_enc.fit(X_train[category_cols])\n",
    "\n",
    "X_train_OE = pd.DataFrame(\n",
    "    ord_enc.transform(X_train[category_cols]), columns=category_cols\n",
    ")\n",
    "X_train_OE.index = X_train.index\n",
    "X_train_OE = pd.concat([X_train_OE, X_train[numeric_cols]], axis=1)\n",
    "\n",
    "X_test_OE = pd.DataFrame(\n",
    "    ord_enc.transform(X_test[category_cols]), columns=category_cols\n",
    ")\n",
    "X_test_OE.index = X_test.index\n",
    "X_test_OE = pd.concat([X_test_OE, X_test[numeric_cols]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 本节新增第三方库\n",
    "from joblib import dump, load\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from hyperopt import hp, fmin, tpe\n",
    "from numpy.random import RandomState\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VotingClassifier_threshold(BaseEstimator, ClassifierMixin, TransformerMixin):\n",
    "    def __init__(self, estimators, voting=\"hard\", weights=None, thr=0.5):\n",
    "        self.estimators = estimators\n",
    "        self.voting = voting\n",
    "        self.weights = weights\n",
    "        self.thr = thr\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        VC = VotingClassifier(\n",
    "            estimators=self.estimators, voting=self.voting, weights=self.weights\n",
    "        )\n",
    "\n",
    "        VC.fit(X, y)\n",
    "        self.clf = VC\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.clf.predict_proba(X) if self.voting == \"soft\" else None\n",
    "\n",
    "    def predict(self, X):\n",
    "        return (\n",
    "            (self.clf.predict_proba(X)[:, 1] >= self.thr) * 1\n",
    "            if self.voting == \"soft\"\n",
    "            else self.clf.predict(X)\n",
    "        )\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return accuracy_score(self.predict(X), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化KFold评估器\n",
    "kf = KFold(n_splits=5, random_state=12, shuffle=True)\n",
    "\n",
    "# 重置训练集和测试集的index\n",
    "X_train_OE = X_train_OE.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "\n",
    "train_part_index_l = []\n",
    "eval_index_l = []\n",
    "\n",
    "for train_part_index, eval_index in kf.split(X_train_OE, y_train):\n",
    "    train_part_index_l.append(train_part_index)\n",
    "    eval_index_l.append(eval_index)\n",
    "\n",
    "# 训练集特征\n",
    "X_train1 = X_train_OE.loc[train_part_index_l[0]]\n",
    "X_train2 = X_train_OE.loc[train_part_index_l[1]]\n",
    "X_train3 = X_train_OE.loc[train_part_index_l[2]]\n",
    "X_train4 = X_train_OE.loc[train_part_index_l[3]]\n",
    "X_train5 = X_train_OE.loc[train_part_index_l[4]]\n",
    "\n",
    "# 验证集特征\n",
    "X_eval1 = X_train_OE.loc[eval_index_l[0]]\n",
    "X_eval2 = X_train_OE.loc[eval_index_l[1]]\n",
    "X_eval3 = X_train_OE.loc[eval_index_l[2]]\n",
    "X_eval4 = X_train_OE.loc[eval_index_l[3]]\n",
    "X_eval5 = X_train_OE.loc[eval_index_l[4]]\n",
    "\n",
    "# 训练集标签\n",
    "y_train1 = y_train.loc[train_part_index_l[0]]\n",
    "y_train2 = y_train.loc[train_part_index_l[1]]\n",
    "y_train3 = y_train.loc[train_part_index_l[2]]\n",
    "y_train4 = y_train.loc[train_part_index_l[3]]\n",
    "y_train5 = y_train.loc[train_part_index_l[4]]\n",
    "\n",
    "# 验证集标签\n",
    "y_eval1 = y_train.loc[eval_index_l[0]]\n",
    "y_eval2 = y_train.loc[eval_index_l[1]]\n",
    "y_eval3 = y_train.loc[eval_index_l[2]]\n",
    "y_eval4 = y_train.loc[eval_index_l[3]]\n",
    "y_eval5 = y_train.loc[eval_index_l[4]]\n",
    "\n",
    "train_set = [\n",
    "    (X_train1, y_train1),\n",
    "    (X_train2, y_train2),\n",
    "    (X_train3, y_train3),\n",
    "    (X_train4, y_train4),\n",
    "    (X_train5, y_train5),\n",
    "]\n",
    "\n",
    "eval_set = [\n",
    "    (X_eval1, y_eval1),\n",
    "    (X_eval2, y_eval2),\n",
    "    (X_eval3, y_eval3),\n",
    "    (X_eval4, y_eval4),\n",
    "    (X_eval5, y_eval5),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机森林模型组\n",
    "grid_RF_1 = load(\"./model/grid_RF_1.joblib\")\n",
    "grid_RF_2 = load(\"./model/grid_RF_2.joblib\")\n",
    "grid_RF_3 = load(\"./model/grid_RF_3.joblib\")\n",
    "grid_RF_4 = load(\"./model/grid_RF_4.joblib\")\n",
    "grid_RF_5 = load(\"./model/grid_RF_5.joblib\")\n",
    "\n",
    "RF_1 = grid_RF_1.best_estimator_\n",
    "RF_2 = grid_RF_2.best_estimator_\n",
    "RF_3 = grid_RF_3.best_estimator_\n",
    "RF_4 = grid_RF_4.best_estimator_\n",
    "RF_5 = grid_RF_5.best_estimator_\n",
    "\n",
    "RF_l = [RF_1, RF_2, RF_3, RF_4, RF_5]\n",
    "\n",
    "# 决策树模型组\n",
    "grid_tree_1 = load(\"./model/grid_tree_1.joblib\")\n",
    "grid_tree_2 = load(\"./model/grid_tree_2.joblib\")\n",
    "grid_tree_3 = load(\"./model/grid_tree_3.joblib\")\n",
    "grid_tree_4 = load(\"./model/grid_tree_4.joblib\")\n",
    "grid_tree_5 = load(\"./model/grid_tree_5.joblib\")\n",
    "\n",
    "tree_1 = grid_tree_1.best_estimator_\n",
    "tree_2 = grid_tree_2.best_estimator_\n",
    "tree_3 = grid_tree_3.best_estimator_\n",
    "tree_4 = grid_tree_4.best_estimator_\n",
    "tree_5 = grid_tree_5.best_estimator_\n",
    "\n",
    "tree_l = [tree_1, tree_2, tree_3, tree_4, tree_5]\n",
    "\n",
    "# 逻辑回归模型组\n",
    "grid_lr_1 = load(\"./model/grid_lr_1.joblib\")\n",
    "grid_lr_2 = load(\"./model/grid_lr_2.joblib\")\n",
    "grid_lr_3 = load(\"./model/grid_lr_3.joblib\")\n",
    "grid_lr_4 = load(\"./model/grid_lr_4.joblib\")\n",
    "grid_lr_5 = load(\"./model/grid_lr_5.joblib\")\n",
    "\n",
    "lr_1 = grid_lr_1.best_estimator_\n",
    "lr_2 = grid_lr_2.best_estimator_\n",
    "lr_3 = grid_lr_3.best_estimator_\n",
    "lr_4 = grid_lr_4.best_estimator_\n",
    "lr_5 = grid_lr_5.best_estimator_\n",
    "\n",
    "lr_l = [lr_1, lr_2, lr_3, lr_4, lr_5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval1_predict_proba_RF = pd.Series(\n",
    "    RF_l[0].predict_proba(X_eval1)[:, 1], index=X_eval1.index\n",
    ")\n",
    "eval2_predict_proba_RF = pd.Series(\n",
    "    RF_l[1].predict_proba(X_eval2)[:, 1], index=X_eval2.index\n",
    ")\n",
    "eval3_predict_proba_RF = pd.Series(\n",
    "    RF_l[2].predict_proba(X_eval3)[:, 1], index=X_eval3.index\n",
    ")\n",
    "eval4_predict_proba_RF = pd.Series(\n",
    "    RF_l[3].predict_proba(X_eval4)[:, 1], index=X_eval4.index\n",
    ")\n",
    "eval5_predict_proba_RF = pd.Series(\n",
    "    RF_l[4].predict_proba(X_eval5)[:, 1], index=X_eval5.index\n",
    ")\n",
    "\n",
    "eval_predict_proba_RF = pd.concat(\n",
    "    [\n",
    "        eval1_predict_proba_RF,\n",
    "        eval2_predict_proba_RF,\n",
    "        eval3_predict_proba_RF,\n",
    "        eval4_predict_proba_RF,\n",
    "        eval5_predict_proba_RF,\n",
    "    ]\n",
    ").sort_index()\n",
    "\n",
    "eval1_predict_proba_tree = pd.Series(\n",
    "    tree_l[0].predict_proba(X_eval1)[:, 1], index=X_eval1.index\n",
    ")\n",
    "eval2_predict_proba_tree = pd.Series(\n",
    "    tree_l[1].predict_proba(X_eval2)[:, 1], index=X_eval2.index\n",
    ")\n",
    "eval3_predict_proba_tree = pd.Series(\n",
    "    tree_l[2].predict_proba(X_eval3)[:, 1], index=X_eval3.index\n",
    ")\n",
    "eval4_predict_proba_tree = pd.Series(\n",
    "    tree_l[3].predict_proba(X_eval4)[:, 1], index=X_eval4.index\n",
    ")\n",
    "eval5_predict_proba_tree = pd.Series(\n",
    "    tree_l[4].predict_proba(X_eval5)[:, 1], index=X_eval5.index\n",
    ")\n",
    "\n",
    "eval_predict_proba_tree = pd.concat(\n",
    "    [\n",
    "        eval1_predict_proba_tree,\n",
    "        eval2_predict_proba_tree,\n",
    "        eval3_predict_proba_tree,\n",
    "        eval4_predict_proba_tree,\n",
    "        eval5_predict_proba_tree,\n",
    "    ]\n",
    ").sort_index()\n",
    "\n",
    "eval1_predict_proba_lr = pd.Series(\n",
    "    lr_l[0].predict_proba(X_eval1)[:, 1], index=X_eval1.index\n",
    ")\n",
    "eval2_predict_proba_lr = pd.Series(\n",
    "    lr_l[1].predict_proba(X_eval2)[:, 1], index=X_eval2.index\n",
    ")\n",
    "eval3_predict_proba_lr = pd.Series(\n",
    "    lr_l[2].predict_proba(X_eval3)[:, 1], index=X_eval3.index\n",
    ")\n",
    "eval4_predict_proba_lr = pd.Series(\n",
    "    lr_l[3].predict_proba(X_eval4)[:, 1], index=X_eval4.index\n",
    ")\n",
    "eval5_predict_proba_lr = pd.Series(\n",
    "    lr_l[4].predict_proba(X_eval5)[:, 1], index=X_eval5.index\n",
    ")\n",
    "\n",
    "eval_predict_proba_lr = pd.concat(\n",
    "    [\n",
    "        eval1_predict_proba_lr,\n",
    "        eval2_predict_proba_lr,\n",
    "        eval3_predict_proba_lr,\n",
    "        eval4_predict_proba_lr,\n",
    "        eval5_predict_proba_lr,\n",
    "    ]\n",
    ").sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict_proba_RF = [\n",
    "    RF_l[i].predict_proba(X_test_OE)[:, 1] for i in range(5)\n",
    "]\n",
    "test_predict_proba_RF = np.array(test_predict_proba_RF)\n",
    "test_predict_proba_RF = test_predict_proba_RF.mean(0)\n",
    "\n",
    "test_predict_proba_tree = [\n",
    "    tree_l[i].predict_proba(X_test_OE)[:, 1] for i in range(5)\n",
    "]\n",
    "test_predict_proba_tree = np.array(test_predict_proba_tree)\n",
    "test_predict_proba_tree = test_predict_proba_tree.mean(0)\n",
    "\n",
    "test_predict_proba_lr = [\n",
    "    lr_l[i].predict_proba(X_test_OE)[:, 1] for i in range(5)\n",
    "]\n",
    "test_predict_proba_lr = np.array(test_predict_proba_lr)\n",
    "test_predict_proba_lr = test_predict_proba_lr.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8761832639151836, 0.7864849517319704)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic = LogisticRegression()\n",
    "tree = DecisionTreeClassifier()\n",
    "RF = RandomForestClassifier()\n",
    "\n",
    "estimators = [(\"lr\", logistic), (\"tree\", tree), (\"rf\", RF)]\n",
    "clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "\n",
    "clf.fit(X_train_OE, y_train)\n",
    "\n",
    "clf.score(X_train_OE, y_train), clf.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8256342294585385, 0.7898921067575241)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_search = load(\"./model/grid_lr_1.joblib\")\n",
    "tree_model = load(\"./model/tree_model.joblib\")\n",
    "RF_0 = load(\"./model/RF_0.joblib\")\n",
    "\n",
    "estimators = [\n",
    "    (\"lr\", logistic_search.best_estimator_),\n",
    "    (\"tree\", tree_model),\n",
    "    (\"rf\", RF_0),\n",
    "]\n",
    "\n",
    "clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "\n",
    "clf.fit(X_train_OE, y_train)\n",
    "\n",
    "clf.score(X_train_OE, y_train), clf.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr_oof</th>\n",
       "      <th>tree_oof</th>\n",
       "      <th>RF_oof</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.011289</td>\n",
       "      <td>0.037669</td>\n",
       "      <td>0.044787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.543190</td>\n",
       "      <td>0.787986</td>\n",
       "      <td>0.572187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.151200</td>\n",
       "      <td>0.222819</td>\n",
       "      <td>0.161815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.273393</td>\n",
       "      <td>0.259434</td>\n",
       "      <td>0.250871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.158399</td>\n",
       "      <td>0.107345</td>\n",
       "      <td>0.122533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5277</th>\n",
       "      <td>0.062756</td>\n",
       "      <td>0.062959</td>\n",
       "      <td>0.082653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5278</th>\n",
       "      <td>0.346367</td>\n",
       "      <td>0.222819</td>\n",
       "      <td>0.346562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5279</th>\n",
       "      <td>0.688556</td>\n",
       "      <td>0.438538</td>\n",
       "      <td>0.551481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5280</th>\n",
       "      <td>0.050627</td>\n",
       "      <td>0.066419</td>\n",
       "      <td>0.049011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5281</th>\n",
       "      <td>0.005330</td>\n",
       "      <td>0.026367</td>\n",
       "      <td>0.002783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5282 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lr_oof  tree_oof    RF_oof\n",
       "0     0.011289  0.037669  0.044787\n",
       "1     0.543190  0.787986  0.572187\n",
       "2     0.151200  0.222819  0.161815\n",
       "3     0.273393  0.259434  0.250871\n",
       "4     0.158399  0.107345  0.122533\n",
       "...        ...       ...       ...\n",
       "5277  0.062756  0.062959  0.082653\n",
       "5278  0.346367  0.222819  0.346562\n",
       "5279  0.688556  0.438538  0.551481\n",
       "5280  0.050627  0.066419  0.049011\n",
       "5281  0.005330  0.026367  0.002783\n",
       "\n",
       "[5282 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stack_oof = pd.DataFrame(\n",
    "    {\n",
    "        \"lr_oof\": eval_predict_proba_lr,\n",
    "        \"tree_oof\": eval_predict_proba_tree,\n",
    "        \"RF_oof\": eval_predict_proba_RF,\n",
    "    }\n",
    ")\n",
    "train_stack_oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr_test</th>\n",
       "      <th>tree_test</th>\n",
       "      <th>RF_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.039438</td>\n",
       "      <td>0.046473</td>\n",
       "      <td>0.029220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.238789</td>\n",
       "      <td>0.158900</td>\n",
       "      <td>0.311980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005101</td>\n",
       "      <td>0.046473</td>\n",
       "      <td>0.016244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.031015</td>\n",
       "      <td>0.046473</td>\n",
       "      <td>0.025769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.059170</td>\n",
       "      <td>0.051573</td>\n",
       "      <td>0.035476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756</th>\n",
       "      <td>0.177800</td>\n",
       "      <td>0.212513</td>\n",
       "      <td>0.193367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1757</th>\n",
       "      <td>0.034432</td>\n",
       "      <td>0.046473</td>\n",
       "      <td>0.048821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1758</th>\n",
       "      <td>0.130264</td>\n",
       "      <td>0.158900</td>\n",
       "      <td>0.145346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1759</th>\n",
       "      <td>0.500205</td>\n",
       "      <td>0.437401</td>\n",
       "      <td>0.530686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1760</th>\n",
       "      <td>0.065774</td>\n",
       "      <td>0.130399</td>\n",
       "      <td>0.106832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1761 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       lr_test  tree_test   RF_test\n",
       "0     0.039438   0.046473  0.029220\n",
       "1     0.238789   0.158900  0.311980\n",
       "2     0.005101   0.046473  0.016244\n",
       "3     0.031015   0.046473  0.025769\n",
       "4     0.059170   0.051573  0.035476\n",
       "...        ...        ...       ...\n",
       "1756  0.177800   0.212513  0.193367\n",
       "1757  0.034432   0.046473  0.048821\n",
       "1758  0.130264   0.158900  0.145346\n",
       "1759  0.500205   0.437401  0.530686\n",
       "1760  0.065774   0.130399  0.106832\n",
       "\n",
       "[1761 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_stack = pd.DataFrame(\n",
    "    {\n",
    "        \"lr_test\": test_predict_proba_lr,\n",
    "        \"tree_test\": test_predict_proba_tree,\n",
    "        \"RF_test\": test_predict_proba_RF,\n",
    "    }\n",
    ")\n",
    "\n",
    "test_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_final = LogisticRegression().fit(train_stack_oof, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8176826959485044, 0.7950028392958546)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_final.score(train_stack_oof, y_train), lr_final.score(test_stack, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cross(X_train, y_train, X_test, estimators, n_splits=5, random_state=12):\n",
    "    X = X_train.reset_index(drop=True)\n",
    "    y = y_train.reset_index(drop=True)\n",
    "\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "    m = X.shape[0]\n",
    "    n = len(estimators)\n",
    "    m_test = X_test.shape[0]\n",
    "\n",
    "    columns = [f'{estimator[0]}_oof' for estimator in estimators]\n",
    "    train_oof = pd.DataFrame(np.zeros((m, n)), columns=columns)\n",
    "\n",
    "    columns = [f\"{estimator[0]}_predict\" for estimator in estimators]\n",
    "    test_predict = pd.DataFrame(np.zeros((m_test, n)), columns=columns)\n",
    "\n",
    "    for estimator in estimators:\n",
    "        model = estimator[1]\n",
    "        oof_colName = f'{estimator[0]}_oof'\n",
    "        predict_colName = f\"{estimator[0]}_predict\"\n",
    "        for train_part_index, eval_index in kf.split(X, y):\n",
    "            X_train_part = X.loc[train_part_index]\n",
    "            y_train_part = y.loc[train_part_index]\n",
    "            model.fit(X_train_part, y_train_part)\n",
    "\n",
    "            X_eval_part = X.loc[eval_index]\n",
    "\n",
    "            train_oof[oof_colName].loc[eval_index] = model.predict_proba(X_eval_part)[\n",
    "                :, 1\n",
    "            ]\n",
    "            test_predict[predict_colName] += (\n",
    "                model.predict_proba(X_test)[:, 1] / n_splits\n",
    "            )\n",
    "    return train_oof, test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    (\"lr\", logistic_search.best_estimator_),\n",
    "    (\"tree\", tree_model),\n",
    "    (\"rf\", RF_0),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_oof, test_predict = train_cross(\n",
    "    X_train_OE,\n",
    "    y_train,\n",
    "    X_test_OE,\n",
    "    estimators=estimators\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr_oof</th>\n",
       "      <th>tree_oof</th>\n",
       "      <th>rf_oof</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.011289</td>\n",
       "      <td>0.065380</td>\n",
       "      <td>0.064009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.538713</td>\n",
       "      <td>0.787986</td>\n",
       "      <td>0.623811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.149283</td>\n",
       "      <td>0.222819</td>\n",
       "      <td>0.186379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.273393</td>\n",
       "      <td>0.234201</td>\n",
       "      <td>0.243126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.158399</td>\n",
       "      <td>0.211248</td>\n",
       "      <td>0.158017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5277</th>\n",
       "      <td>0.070529</td>\n",
       "      <td>0.062959</td>\n",
       "      <td>0.096975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5278</th>\n",
       "      <td>0.349486</td>\n",
       "      <td>0.222819</td>\n",
       "      <td>0.257227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5279</th>\n",
       "      <td>0.685251</td>\n",
       "      <td>0.503722</td>\n",
       "      <td>0.478084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5280</th>\n",
       "      <td>0.051630</td>\n",
       "      <td>0.066419</td>\n",
       "      <td>0.058595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5281</th>\n",
       "      <td>0.004848</td>\n",
       "      <td>0.026367</td>\n",
       "      <td>0.006766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5282 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lr_oof  tree_oof    rf_oof\n",
       "0     0.011289  0.065380  0.064009\n",
       "1     0.538713  0.787986  0.623811\n",
       "2     0.149283  0.222819  0.186379\n",
       "3     0.273393  0.234201  0.243126\n",
       "4     0.158399  0.211248  0.158017\n",
       "...        ...       ...       ...\n",
       "5277  0.070529  0.062959  0.096975\n",
       "5278  0.349486  0.222819  0.257227\n",
       "5279  0.685251  0.503722  0.478084\n",
       "5280  0.051630  0.066419  0.058595\n",
       "5281  0.004848  0.026367  0.006766\n",
       "\n",
       "[5282 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr_predict</th>\n",
       "      <th>tree_predict</th>\n",
       "      <th>rf_predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.040030</td>\n",
       "      <td>0.052015</td>\n",
       "      <td>0.023194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.242061</td>\n",
       "      <td>0.091196</td>\n",
       "      <td>0.307647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004933</td>\n",
       "      <td>0.052015</td>\n",
       "      <td>0.006359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.031792</td>\n",
       "      <td>0.052015</td>\n",
       "      <td>0.012658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.061342</td>\n",
       "      <td>0.069881</td>\n",
       "      <td>0.049331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756</th>\n",
       "      <td>0.173789</td>\n",
       "      <td>0.223305</td>\n",
       "      <td>0.192447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1757</th>\n",
       "      <td>0.035180</td>\n",
       "      <td>0.052015</td>\n",
       "      <td>0.066831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1758</th>\n",
       "      <td>0.136799</td>\n",
       "      <td>0.091196</td>\n",
       "      <td>0.160348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1759</th>\n",
       "      <td>0.500012</td>\n",
       "      <td>0.484657</td>\n",
       "      <td>0.591940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1760</th>\n",
       "      <td>0.067926</td>\n",
       "      <td>0.091196</td>\n",
       "      <td>0.093765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1761 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      lr_predict  tree_predict  rf_predict\n",
       "0       0.040030      0.052015    0.023194\n",
       "1       0.242061      0.091196    0.307647\n",
       "2       0.004933      0.052015    0.006359\n",
       "3       0.031792      0.052015    0.012658\n",
       "4       0.061342      0.069881    0.049331\n",
       "...          ...           ...         ...\n",
       "1756    0.173789      0.223305    0.192447\n",
       "1757    0.035180      0.052015    0.066831\n",
       "1758    0.136799      0.091196    0.160348\n",
       "1759    0.500012      0.484657    0.591940\n",
       "1760    0.067926      0.091196    0.093765\n",
       "\n",
       "[1761 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8120030291556228, 0.7881885292447472)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression().fit(train_oof, y_train)\n",
    "clf.score(train_oof, y_train), clf.score(test_predict, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr_oof</th>\n",
       "      <th>tree_oof</th>\n",
       "      <th>rf_oof</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.040030</td>\n",
       "      <td>0.052015</td>\n",
       "      <td>0.023194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.242061</td>\n",
       "      <td>0.091196</td>\n",
       "      <td>0.307647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004933</td>\n",
       "      <td>0.052015</td>\n",
       "      <td>0.006359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.031792</td>\n",
       "      <td>0.052015</td>\n",
       "      <td>0.012658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.061342</td>\n",
       "      <td>0.069881</td>\n",
       "      <td>0.049331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756</th>\n",
       "      <td>0.173789</td>\n",
       "      <td>0.223305</td>\n",
       "      <td>0.192447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1757</th>\n",
       "      <td>0.035180</td>\n",
       "      <td>0.052015</td>\n",
       "      <td>0.066831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1758</th>\n",
       "      <td>0.136799</td>\n",
       "      <td>0.091196</td>\n",
       "      <td>0.160348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1759</th>\n",
       "      <td>0.500012</td>\n",
       "      <td>0.484657</td>\n",
       "      <td>0.591940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1760</th>\n",
       "      <td>0.067926</td>\n",
       "      <td>0.091196</td>\n",
       "      <td>0.093765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1761 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lr_oof  tree_oof    rf_oof\n",
       "0     0.040030  0.052015  0.023194\n",
       "1     0.242061  0.091196  0.307647\n",
       "2     0.004933  0.052015  0.006359\n",
       "3     0.031792  0.052015  0.012658\n",
       "4     0.061342  0.069881  0.049331\n",
       "...        ...       ...       ...\n",
       "1756  0.173789  0.223305  0.192447\n",
       "1757  0.035180  0.052015  0.066831\n",
       "1758  0.136799  0.091196  0.160348\n",
       "1759  0.500012  0.484657  0.591940\n",
       "1760  0.067926  0.091196  0.093765\n",
       "\n",
       "[1761 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_colname = test_predict.columns\n",
    "test_predict.columns = train_oof.columns\n",
    "test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results of LR-final:\n",
      "Train-Accuracy: 0.812003, Test-Accuracy: 0.788189\n",
      "The results of tree-final:\n",
      "Train-Accuracy: 0.999432, Test-Accuracy: 0.723453\n",
      "The results of KNN-final:\n",
      "Train-Accuracy: 0.854601, Test-Accuracy: 0.762635\n",
      "The results of SVM-final:\n",
      "Train-Accuracy: 0.809353, Test-Accuracy: 0.789892\n",
      "The results of GaussianNB-final:\n",
      "Train-Accuracy: 0.798372, Test-Accuracy: 0.781942\n",
      "The results of Bagging-final:\n",
      "Train-Accuracy: 0.981257, Test-Accuracy: 0.749574\n",
      "The results of RandomForest-final:\n",
      "Train-Accuracy: 0.999432, Test-Accuracy: 0.766610\n",
      "The results of AdaBoost-final:\n",
      "Train-Accuracy: 0.811814, Test-Accuracy: 0.789892\n",
      "The results of GBDT-final:\n",
      "Train-Accuracy: 0.824877, Test-Accuracy: 0.785349\n",
      "The results of XGB-final:\n",
      "Train-Accuracy: 0.913858, Test-Accuracy: 0.768881\n"
     ]
    }
   ],
   "source": [
    "# 逻辑回归\n",
    "lr = LogisticRegression().fit(train_oof, y_train)\n",
    "print(\"The results of LR-final:\")\n",
    "print(\n",
    "    \"Train-Accuracy: %f, Test-Accuracy: %f\"\n",
    "    % (lr.score(train_oof, y_train), lr.score(test_predict, y_test))\n",
    ")\n",
    "\n",
    "# 决策树\n",
    "tree = DecisionTreeClassifier().fit(train_oof, y_train)\n",
    "print(\"The results of tree-final:\")\n",
    "print(\n",
    "    \"Train-Accuracy: %f, Test-Accuracy: %f\"\n",
    "    % (tree.score(train_oof, y_train), tree.score(test_predict, y_test))\n",
    ")\n",
    "\n",
    "# KNN最近邻分类器\n",
    "from sklearn import neighbors\n",
    "\n",
    "KNN = neighbors.KNeighborsClassifier().fit(train_oof, y_train)\n",
    "print(\"The results of KNN-final:\")\n",
    "print(\n",
    "    \"Train-Accuracy: %f, Test-Accuracy: %f\"\n",
    "    % (KNN.score(train_oof, y_train), KNN.score(test_predict, y_test))\n",
    ")\n",
    "\n",
    "# SVM支持向量机\n",
    "from sklearn import svm\n",
    "\n",
    "SVM = svm.SVC().fit(train_oof, y_train)\n",
    "print(\"The results of SVM-final:\")\n",
    "print(\n",
    "    \"Train-Accuracy: %f, Test-Accuracy: %f\"\n",
    "    % (SVM.score(train_oof, y_train), SVM.score(test_predict, y_test))\n",
    ")\n",
    "\n",
    "# 朴素贝叶斯/高斯贝叶斯\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB().fit(train_oof, y_train)\n",
    "print(\"The results of GaussianNB-final:\")\n",
    "print(\n",
    "    \"Train-Accuracy: %f, Test-Accuracy: %f\"\n",
    "    % (gnb.score(train_oof, y_train), gnb.score(test_predict, y_test))\n",
    ")\n",
    "\n",
    "# Bagging\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bagging = BaggingClassifier().fit(train_oof, y_train)\n",
    "print(\"The results of Bagging-final:\")\n",
    "print(\n",
    "    \"Train-Accuracy: %f, Test-Accuracy: %f\"\n",
    "    % (bagging.score(train_oof, y_train), bagging.score(test_predict, y_test))\n",
    ")\n",
    "\n",
    "# 随机森林\n",
    "RFC = RandomForestClassifier().fit(train_oof, y_train)\n",
    "print(\"The results of RandomForest-final:\")\n",
    "print(\n",
    "    \"Train-Accuracy: %f, Test-Accuracy: %f\"\n",
    "    % (RFC.score(train_oof, y_train), RFC.score(test_predict, y_test))\n",
    ")\n",
    "\n",
    "# AdaBoost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ABC = AdaBoostClassifier().fit(train_oof, y_train)\n",
    "print(\"The results of AdaBoost-final:\")\n",
    "print(\n",
    "    \"Train-Accuracy: %f, Test-Accuracy: %f\"\n",
    "    % (ABC.score(train_oof, y_train), ABC.score(test_predict, y_test))\n",
    ")\n",
    "\n",
    "# GBDT\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "GBC = GradientBoostingClassifier().fit(train_oof, y_train)\n",
    "print(\"The results of GBDT-final:\")\n",
    "print(\n",
    "    \"Train-Accuracy: %f, Test-Accuracy: %f\"\n",
    "    % (GBC.score(train_oof, y_train), GBC.score(test_predict, y_test))\n",
    ")\n",
    "\n",
    "# XGB\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "XGB = XGBClassifier().fit(train_oof, y_train)\n",
    "print(\"The results of XGB-final:\")\n",
    "print(\n",
    "    \"Train-Accuracy: %f, Test-Accuracy: %f\"\n",
    "    % (XGB.score(train_oof, y_train), XGB.score(test_predict, y_test))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr_predict</th>\n",
       "      <th>tree_predict</th>\n",
       "      <th>rf_predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.040030</td>\n",
       "      <td>0.052015</td>\n",
       "      <td>0.023194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.242061</td>\n",
       "      <td>0.091196</td>\n",
       "      <td>0.307647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004933</td>\n",
       "      <td>0.052015</td>\n",
       "      <td>0.006359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.031792</td>\n",
       "      <td>0.052015</td>\n",
       "      <td>0.012658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.061342</td>\n",
       "      <td>0.069881</td>\n",
       "      <td>0.049331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756</th>\n",
       "      <td>0.173789</td>\n",
       "      <td>0.223305</td>\n",
       "      <td>0.192447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1757</th>\n",
       "      <td>0.035180</td>\n",
       "      <td>0.052015</td>\n",
       "      <td>0.066831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1758</th>\n",
       "      <td>0.136799</td>\n",
       "      <td>0.091196</td>\n",
       "      <td>0.160348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1759</th>\n",
       "      <td>0.500012</td>\n",
       "      <td>0.484657</td>\n",
       "      <td>0.591940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1760</th>\n",
       "      <td>0.067926</td>\n",
       "      <td>0.091196</td>\n",
       "      <td>0.093765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1761 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      lr_predict  tree_predict  rf_predict\n",
       "0       0.040030      0.052015    0.023194\n",
       "1       0.242061      0.091196    0.307647\n",
       "2       0.004933      0.052015    0.006359\n",
       "3       0.031792      0.052015    0.012658\n",
       "4       0.061342      0.069881    0.049331\n",
       "...          ...           ...         ...\n",
       "1756    0.173789      0.223305    0.192447\n",
       "1757    0.035180      0.052015    0.066831\n",
       "1758    0.136799      0.091196    0.160348\n",
       "1759    0.500012      0.484657    0.591940\n",
       "1760    0.067926      0.091196    0.093765\n",
       "\n",
       "[1761 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predict.columns = old_colname\n",
    "test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8320711851571374, 0.7745599091425327)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN = neighbors.KNeighborsClassifier(n_neighbors=9).fit(train_oof, y_train)\n",
    "KNN.score(train_oof, y_train), KNN.score(test_predict, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_param = [\n",
    "    {\n",
    "        \"thr\": np.arange(0.1, 1, 0.1).tolist(),\n",
    "        \"penalty\": [\"l1\"],\n",
    "        \"C\": np.arange(0.1, 1.1, 0.1).tolist(),\n",
    "        \"solver\": ['saga'],\n",
    "    },\n",
    "    {\n",
    "        \"thr\": np.arange(0.1, 1, 0.1).tolist(),\n",
    "        \"penalty\": [\"l2\"],\n",
    "        \"C\": np.arange(0.1, 1.1, 0.1).tolist(),\n",
    "        \"solver\": [\"lbfgs\", \"newton-cg\", \"sag\", \"saga\"],\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_final = logit_threshold(max_iter=int(1e6))\n",
    "\n",
    "lfg = GridSearchCV(\n",
    "    estimator=logistic_final,\n",
    "    param_grid=logistic_param,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1,\n",
    ").fit(train_oof, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8123812032338522"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lfg.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.5, 'penalty': 'l1', 'solver': 'saga', 'thr': 0.5}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lfg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8129496402877698, 0.7881885292447472)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lfg.score(train_oof, y_train), lfg.score(test_predict, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,\n",
       "                                       14, 15],\n",
       "                         &#x27;max_leaf_nodes&#x27;: [6, 7, 8, 9, 10, 11, 12, 13, 14, 15,\n",
       "                                            16, 17, 18, 19, 20, 21, 22, 23, 24,\n",
       "                                            25, 26, 27, 28, 29],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 3],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 3, 4]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,\n",
       "                                       14, 15],\n",
       "                         &#x27;max_leaf_nodes&#x27;: [6, 7, 8, 9, 10, 11, 12, 13, 14, 15,\n",
       "                                            16, 17, 18, 19, 20, 21, 22, 23, 24,\n",
       "                                            25, 26, 27, 28, 29],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 3],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 3, 4]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "             param_grid={'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,\n",
       "                                       14, 15],\n",
       "                         'max_leaf_nodes': [6, 7, 8, 9, 10, 11, 12, 13, 14, 15,\n",
       "                                            16, 17, 18, 19, 20, 21, 22, 23, 24,\n",
       "                                            25, 26, 27, 28, 29],\n",
       "                         'min_samples_leaf': [1, 2, 3],\n",
       "                         'min_samples_split': [2, 3, 4]})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_final = DecisionTreeClassifier()\n",
    "\n",
    "tree_param = {\n",
    "    \"max_depth\": np.arange(2, 16, 1).tolist(),\n",
    "    \"min_samples_split\": np.arange(2, 5, 1).tolist(),\n",
    "    \"min_samples_leaf\": np.arange(1, 4, 1).tolist(),\n",
    "    \"max_leaf_nodes\": np.arange(6, 30, 1).tolist(),\n",
    "}\n",
    "\n",
    "tfg = GridSearchCV(estimator=tree_final, param_grid=tree_param, n_jobs=-1)\n",
    "tfg.fit(train_oof, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5,\n",
       " 'max_leaf_nodes': 10,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8023461913362576"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfg.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8129496402877698, 0.7853492333901193)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfg.score(train_oof, y_train), tfg.score(test_predict, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.403291940689087\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# 设置超参数空间\n",
    "parameter_space = {\n",
    "    \"n_estimators\": range(10, 21),\n",
    "    \"max_samples\": np.arange(0.1, 1.1, 0.1).tolist(),\n",
    "}\n",
    "\n",
    "# 实例化模型与评估器\n",
    "bagging_final = BaggingClassifier(DecisionTreeClassifier())\n",
    "BG = GridSearchCV(bagging_final, parameter_space, n_jobs=-1)\n",
    "\n",
    "# 模型训练\n",
    "BG.fit(train_oof, y_train)\n",
    "\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_samples': 0.1, 'n_estimators': 16}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BG.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8031032295519049"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BG.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8282847406285498, 0.7739920499716071)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BG.score(train_oof, y_train), BG.score(test_predict, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.265425443649292\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# 设置超参数空间\n",
    "parameter_space = {\n",
    "    \"n_estimators\": range(10, 21),\n",
    "    \"max_samples\": np.arange(0.1, 1.1, 0.1).tolist(),\n",
    "}\n",
    "\n",
    "# 实例化模型与评估器\n",
    "bagging_final = BaggingClassifier(\n",
    "    DecisionTreeClassifier(\n",
    "        max_depth=3, max_leaf_nodes=7, min_samples_leaf=1, min_samples_split=2\n",
    "    )\n",
    ")\n",
    "BG = GridSearchCV(bagging_final, parameter_space, n_jobs=-1)\n",
    "\n",
    "# 模型训练\n",
    "BG.fit(train_oof, y_train)\n",
    "\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_samples': 1.0, 'n_estimators': 15}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BG.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8114353086207391"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BG.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8127603180613404, 0.7876206700738216)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BG.score(train_oof, y_train), BG.score(test_predict, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.38026213645935\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "parameter_space = {\n",
    "    \"n_estimators\": range(10, 21),\n",
    "    \"max_samples\": np.arange(0.1, 1.1, 0.1).tolist(),\n",
    "    \"max_features\": np.arange(0.1, 1.1, 0.1).tolist(),\n",
    "}\n",
    "\n",
    "bagging_final = BaggingClassifier(LogisticRegression())\n",
    "BG = GridSearchCV(bagging_final, parameter_space, n_jobs=-1)\n",
    "\n",
    "BG.fit(train_oof, y_train)\n",
    "\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 1.0, 'max_samples': 0.8, 'n_estimators': 17}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BG.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8131385998107852"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BG.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8118137069291935, 0.7876206700738216)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BG.score(train_oof, y_train), BG.score(test_predict, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.373154640197754\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# 设置超参数空间\n",
    "parameter_space = {\n",
    "    \"n_estimators\": range(10, 21),\n",
    "    \"max_samples\": np.arange(0.1, 1.1, 0.1).tolist(),\n",
    "    \"max_features\": np.arange(0.1, 1.1, 0.1).tolist(),\n",
    "}\n",
    "\n",
    "# 实例化模型与评估器\n",
    "bagging_final = BaggingClassifier(LogisticRegression(penalty=\"l1\", solver=\"saga\"))\n",
    "BG = GridSearchCV(bagging_final, parameter_space, n_jobs=15)\n",
    "\n",
    "# 模型训练\n",
    "BG.fit(train_oof, y_train)\n",
    "\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 0.8, 'max_samples': 0.9, 'n_estimators': 17}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BG.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8137064232676815"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BG.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8116243847027641, 0.7859170925610448)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BG.score(train_oof, y_train), BG.score(test_predict, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.78769421577454\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# 设置超参数空间\n",
    "parameter_space = {\n",
    "    \"n_estimators\": range(10, 101),\n",
    "    \"learning_rate\": np.arange(0.01, 0.55, 0.05).tolist(),\n",
    "    \"algorithm\": [\"SAMME.R\", \"SAMME\"],\n",
    "}\n",
    "\n",
    "# 实例化模型与评估器\n",
    "AB_final = AdaBoostClassifier()\n",
    "abg = GridSearchCV(AB_final, parameter_space, n_jobs=15)\n",
    "\n",
    "# 模型训练\n",
    "abg.fit(train_oof, y_train)\n",
    "\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'SAMME',\n",
       " 'learning_rate': 0.060000000000000005,\n",
       " 'n_estimators': 44}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8114350624763347, 0.7836456558773425)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abg.score(train_oof, y_train), abg.score(test_predict, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.763091802597046\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# 设置超参数空间\n",
    "parameter_space = {\n",
    "    \"n_estimators\": range(10, 51),\n",
    "    \"learning_rate\": np.arange(0.01, 0.51, 0.05).tolist(),\n",
    "    \"algorithm\": [\"SAMME.R\", \"SAMME\"],\n",
    "}\n",
    "\n",
    "# 实例化模型与评估器\n",
    "AB_final = AdaBoostClassifier(LogisticRegression())\n",
    "abg = GridSearchCV(AB_final, parameter_space, n_jobs=-1)\n",
    "\n",
    "# 模型训练\n",
    "abg.fit(train_oof, y_train)\n",
    "\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'SAMME', 'learning_rate': 0.26, 'n_estimators': 29}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.9546480178833\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# 设置超参数空间\n",
    "parameter_space = {\n",
    "    \"n_estimators\": range(1, 31),\n",
    "    \"learning_rate\": np.arange(0.01, 0.51, 0.05).tolist(),\n",
    "    \"algorithm\": [\"SAMME.R\", \"SAMME\"],\n",
    "}\n",
    "\n",
    "# 实例化模型与评估器\n",
    "AB_final = AdaBoostClassifier(LogisticRegression(penalty=\"l1\", solver=\"saga\"))\n",
    "abg = GridSearchCV(AB_final, parameter_space, n_jobs=-1)\n",
    "\n",
    "# 模型训练\n",
    "abg.fit(train_oof, y_train)\n",
    "\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'SAMME.R', 'learning_rate': 0.01, 'n_estimators': 1}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7385460053010223, 0.7228847245883021)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abg.score(train_oof, y_train), abg.score(test_predict, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.07269859313965\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# 设置超参数空间\n",
    "parameter_space = {\n",
    "    \"min_samples_leaf\": range(2, 6),\n",
    "    \"min_samples_split\": range(2, 6),\n",
    "    \"max_depth\": range(5, 8),\n",
    "    \"max_leaf_nodes\": [None] + list(range(20, 25)),\n",
    "    \"n_estimators\": range(6, 11),\n",
    "    \"max_samples\": [None, 0.54, 0.55, 0.56],\n",
    "}\n",
    "\n",
    "# 实例化模型与评估器\n",
    "RF_final = RandomForestClassifier(random_state=12)\n",
    "rfg = GridSearchCV(RF_final, parameter_space, n_jobs=-1)\n",
    "\n",
    "# 模型训练\n",
    "rfg.fit(train_oof, y_train)\n",
    "\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5,\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': 0.56,\n",
       " 'min_samples_leaf': 4,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 10}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8148428625520636, 0.7887563884156729)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfg.score(train_oof, y_train), rfg.score(test_predict, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.zeros(test_predict.shape[0])\n",
    "\n",
    "folds = RepeatedKFold(n_splits=5, n_repeats=2)\n",
    "\n",
    "for trn_idx, val_idx in folds.split(train_oof, y_train):\n",
    "    lr = LogisticRegression(penalty=\"l1\", solver=\"saga\")\n",
    "    lr.fit(train_oof.loc[trn_idx], y_train.loc[trn_idx])\n",
    "    res += lr.predict_proba(test_predict)[:, 1] / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7887563884156729"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score((res >= 0.5) * 1, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.zeros(test_predict.shape[0])\n",
    "\n",
    "folds = RepeatedKFold(n_splits=5, n_repeats=2)\n",
    "\n",
    "for trn_idx, val_idx in folds.split(train_oof, y_train):\n",
    "    tree = DecisionTreeClassifier(\n",
    "        max_depth=3, max_leaf_nodes=7, min_samples_leaf=1, min_samples_split=2\n",
    "    )\n",
    "    tree.fit(train_oof.loc[trn_idx], y_train.loc[trn_idx])\n",
    "    res += tree.predict_proba(test_predict)[:, 1] / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7864849517319704"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score((res >= 0.5) * 1, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7876206700738216"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = np.zeros(test_predict.shape[0])\n",
    "\n",
    "folds = RepeatedKFold(n_splits=5, n_repeats=2, random_state=12)\n",
    "\n",
    "for trn_idx, val_idx in folds.split(train_oof, y_train):\n",
    "    lfg = GridSearchCV(\n",
    "        estimator=logit_threshold(max_iter=int(1e6)),\n",
    "        param_grid=logistic_param,\n",
    "        scoring=\"accuracy\",\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    lfg.fit(train_oof.loc[trn_idx], y_train.loc[trn_idx])\n",
    "    res += lfg.predict_proba(test_predict)[:, 1] / 10\n",
    "\n",
    "accuracy_score((res >= 0.5) * 1, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7864849517319704\n"
     ]
    }
   ],
   "source": [
    "res = np.zeros(test_predict.shape[0])\n",
    "\n",
    "folds = RepeatedKFold(n_splits=5, n_repeats=2, random_state=12)\n",
    "\n",
    "for trn_idx, val_idx in folds.split(train_oof, y_train):\n",
    "    tfg = GridSearchCV(\n",
    "        estimator=DecisionTreeClassifier(), param_grid=tree_param, n_jobs=-1\n",
    "    )\n",
    "    tfg.fit(train_oof.loc[trn_idx], y_train.loc[trn_idx])\n",
    "    res += tfg.predict_proba(test_predict)[:, 1] / 10\n",
    "\n",
    "print(accuracy_score((res >= 0.5) * 1, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8186293070806513, 0.7967064168086314)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 设置超参数空间\n",
    "logistic_param = [\n",
    "    {\n",
    "        \"thr\": np.arange(0.1, 1, 0.1).tolist(),\n",
    "        \"penalty\": [\"l1\"],\n",
    "        \"C\": np.arange(0.1, 1.1, 0.1).tolist(),\n",
    "        \"solver\": [\"saga\"],\n",
    "    },\n",
    "    {\n",
    "        \"thr\": np.arange(0.1, 1, 0.1).tolist(),\n",
    "        \"penalty\": [\"l2\"],\n",
    "        \"C\": np.arange(0.1, 1.1, 0.1).tolist(),\n",
    "        \"solver\": [\"lbfgs\", \"newton-cg\", \"sag\", \"saga\"],\n",
    "    },\n",
    "]\n",
    "\n",
    "# 实例化相关评估器\n",
    "logistic_final = logit_threshold(max_iter=int(1e6))\n",
    "\n",
    "# 执行网格搜索\n",
    "lfg = GridSearchCV(\n",
    "    estimator=logistic_final, param_grid=logistic_param, scoring=\"accuracy\", n_jobs=15\n",
    ").fit(train_stack_oof, y_train)\n",
    "\n",
    "lfg.score(train_stack_oof, y_train), lfg.score(test_stack, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.30000000000000004, 'penalty': 'l1', 'solver': 'saga', 'thr': 0.5}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lfg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8188186293070806, 0.7904599659284497)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 实例化决策树评估器\n",
    "tree_final = DecisionTreeClassifier()\n",
    "\n",
    "tree_param = {\n",
    "    \"max_depth\": np.arange(2, 16, 1).tolist(),\n",
    "    \"min_samples_split\": np.arange(2, 5, 1).tolist(),\n",
    "    \"min_samples_leaf\": np.arange(1, 4, 1).tolist(),\n",
    "    \"max_leaf_nodes\": np.arange(6, 30, 1).tolist(),\n",
    "}\n",
    "\n",
    "# 实例化网格搜索评估器\n",
    "tfg = GridSearchCV(estimator=tree_final, param_grid=tree_param, n_jobs=-1).fit(\n",
    "    train_stack_oof, y_train\n",
    ")\n",
    "\n",
    "tfg.score(train_stack_oof, y_train), tfg.score(test_stack, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 4,\n",
       " 'max_leaf_nodes': 8,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.797274275979557\n"
     ]
    }
   ],
   "source": [
    "# 逻辑回归交叉训练\n",
    "res = np.zeros(test_predict.shape[0])\n",
    "\n",
    "folds = RepeatedKFold(n_splits=5, n_repeats=2, random_state=12)\n",
    "\n",
    "for trn_idx, val_idx in folds.split(train_stack_oof, y_train):\n",
    "    lfg = GridSearchCV(\n",
    "        estimator=logit_threshold(max_iter=int(1e6)),\n",
    "        param_grid=logistic_param,\n",
    "        scoring=\"accuracy\",\n",
    "        n_jobs=15,\n",
    "    )\n",
    "    lfg.fit(train_stack_oof.loc[trn_idx], y_train.loc[trn_idx])\n",
    "    res += lfg.predict_proba(test_stack)[:, 1] / 10\n",
    "\n",
    "print(accuracy_score((res >= 0.5) * 1, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7904599659284497\n"
     ]
    }
   ],
   "source": [
    "# 决策树交叉训练过程\n",
    "res = np.zeros(test_predict.shape[0])\n",
    "\n",
    "folds = RepeatedKFold(n_splits=5, n_repeats=2, random_state=12)\n",
    "\n",
    "for trn_idx, val_idx in folds.split(train_stack_oof, y_train):\n",
    "    tfg = GridSearchCV(\n",
    "        estimator=DecisionTreeClassifier(), param_grid=tree_param, n_jobs=12\n",
    "    )\n",
    "    tfg.fit(train_stack_oof.loc[trn_idx], y_train.loc[trn_idx])\n",
    "    res += tfg.predict_proba(test_stack)[:, 1] / 10\n",
    "\n",
    "print(accuracy_score((res >= 0.5) * 1, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8178720181749337, 0.7967064168086314)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 设置超参数空间\n",
    "parameter_space = {\n",
    "    \"n_estimators\": range(10, 21),\n",
    "    \"max_samples\": np.arange(0.1, 1.1, 0.1).tolist(),\n",
    "    \"max_features\": np.arange(0.1, 1.1, 0.1).tolist(),\n",
    "}\n",
    "\n",
    "# 实例化模型与评估器\n",
    "bagging_final = BaggingClassifier(\n",
    "    LogisticRegression(C=0.3, penalty=\"l1\", solver=\"saga\")\n",
    ")\n",
    "BG = GridSearchCV(bagging_final, parameter_space, n_jobs=15).fit(\n",
    "    train_stack_oof, y_train\n",
    ")\n",
    "\n",
    "BG.score(train_stack_oof, y_train), BG.score(test_stack, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8199545626656569, 0.8006814310051107)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 设置超参数空间\n",
    "parameter_space = {\n",
    "    \"n_estimators\": range(10, 21),\n",
    "    \"max_samples\": np.arange(0.1, 1.1, 0.1).tolist(),\n",
    "}\n",
    "\n",
    "# 实例化模型与评估器\n",
    "bagging_final = BaggingClassifier(\n",
    "    DecisionTreeClassifier(\n",
    "        max_depth=4, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=2\n",
    "    )\n",
    ")\n",
    "BG = GridSearchCV(bagging_final, parameter_space, n_jobs=-1).fit(\n",
    "    train_stack_oof, y_train\n",
    ")\n",
    "\n",
    "BG.score(train_stack_oof, y_train), BG.score(test_stack, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
